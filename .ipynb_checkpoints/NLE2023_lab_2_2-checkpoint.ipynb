{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pq7c607fjXsS"
   },
   "source": [
    "# Week 2: Preprocessing Text (Part 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vo-uSUEwjXsU"
   },
   "outputs": [],
   "source": [
    "#necessary library imports and setup introduced previously\n",
    "\n",
    "import sys\n",
    "import re\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "from itertools import zip_longest\n",
    "import nltk\n",
    "from nltk.corpus import reuters\n",
    "from nltk.tokenize import word_tokenize\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "baDBuSxYlE0Q",
    "outputId": "16518c2b-fcf4-4f44-9eba-a6175af98c37"
   },
   "outputs": [],
   "source": [
    "##uncomment these lines below if working on colab\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-7FNGNyljXsY"
   },
   "source": [
    "## Overview\n",
    "Remember, a raw text document is just a sequence of characters. There are a number of basic steps that are often performed when processing natural language text. In lab sessions this week we are covering some of the basic text pre-processing methods. In the previous notebook, you looked at\n",
    "- <b> segmentation</b> - breaking down large units of text into smaller units such as documents and sentences.\n",
    "- <b> tokenisation</b> - roughly speaking, this involves grouping characters into words;\n",
    "\n",
    "In this notebook, you will be looking at:\n",
    "- <b>case normalisation</b> - this involves converting all of the text into lower case;\n",
    "- <b>stemming</b> - this involves removing a word's inflections to find the stem; and\n",
    "- <b>punctuation and stop-word removal</b> - stop-words are common functions words that in some situations can be ignored.\n",
    "\n",
    "Note that we do not always apply all of the above preprocessing methods; it depends on the application. One of the things that you will be learning about in this module, is when the application of each of these methods is, and is not, appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7l6pjAZljXsY"
   },
   "source": [
    "## Normalising text and removing unimportant tokens\n",
    "In this next section we will consider several methods that pre-process (tokenised) text in ways that are sometimes helpful to 'downstream' processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQbWxHPFjXsZ"
   },
   "source": [
    "### Number and case normalisation\n",
    "Without any kind of normalisation, the tokens `\"help\"` and `\"Help\"` are two distinct types. In some contexts you may not want to distinguish them.\n",
    "\n",
    "Another example, is that `\"1998\"` and `\"1999\"` count as distinct types. There are situations where there is no need to distinction between different numbers.\n",
    "\n",
    "The following code performs case normalisation and replaces tokens that consist of digits by \"NUM\".\n",
    "- Python provides a [number of functions](http://docs.python.org/library/stdtypes.html#string-methods), which you can call in order to analyse their content, or produce new strings from them.\n",
    "- The code uses a [list comprehension](http://docs.python.org/tutorial/datastructures.html#list-comprehensions) to build a new list by looping through and filtering items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GGESwOoSjXsZ",
    "outputId": "955246c1-9cb7-4edd-a573-716d11235bed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'cake', 'is', 'a', 'lie']\n",
      "['in', 'the', 'year', 'NUM', 'of', 'the', 'fourth', 'age', ',', 'after', 'NUM', 'years', 'as', 'king', ',', 'aragorn', 'died', 'at', 'the', 'age', 'of', 'NUM']\n"
     ]
    }
   ],
   "source": [
    "tokens = [\"The\",\"cake\",\"is\",\"a\",\"LIE\"]      #a list of tokens, some of which contain uppercase letters\n",
    "print([token.lower() for token in tokens])   #print newly created list of all lowercase tokens\n",
    "\n",
    "numbers = ['in', 'the', 'year', '120', 'of', 'the', 'fourth', 'age', ',', 'after', '120', 'years', 'as', 'king', ',' , 'aragorn', 'died', 'at', 'the', 'age', 'of', '210']\n",
    "print([\"NUM\" if token.isdigit() else token for token in numbers])  #replace all number tokens with \"NUM\" in a new list of tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S4uE15AXjXsc"
   },
   "source": [
    "### Exercise 1.1\n",
    "- Write a function <code>number_normalise</code> which\n",
    "    * replaces numbers with NUM;\n",
    "    * and replaces tokens such as `\"4th\"`, `\"1st\"` and `\"22nd\"` with `\"Nth\"`.\n",
    "- Test your code on the list `[\"Within\",\"5\",\"minutes\",\",\",\"the\", \"1st\", \"and\", \"2nd\", \"placed\", \"runners\", \"lapped\", \"the\", \"5th\",\".\"]`.\n",
    "- Check that the token `\"and\"` isn't changed to `\"Nth\"`.\n",
    "- You will find [this page](http://docs.python.org/library/stdtypes.html#string-methods) useful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "62J_VD4GjXsd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Within', 'NUM', 'minutes', ',', 'the', 'Nth', 'and', 'Nth', 'placed', 'runners', 'lapped', 'the', 'Nth', '.']\n"
     ]
    }
   ],
   "source": [
    "tokens = [\"Within\",\"5\",\"minutes\",\",\",\"the\", \"1st\", \"and\", \"2nd\", \"placed\", \"runners\", \"lapped\", \"the\", \"5th\",\".\"]\n",
    "def number_normalise(tokens):\n",
    "    normalised1=[\"Nth\" if (token.endswith((\"nd\",\"st\",\"th\",\"rd\")) and token[:-2].isdigit()) else token for token in tokens]\n",
    "    normalised2=[\"NUM\" if token.isdigit() else token for token in normalised1]\n",
    "    return normalised2\n",
    "\n",
    "print(number_normalise(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eTBYKFVVjXsj"
   },
   "source": [
    "### Exercise 1.2\n",
    "- Complete the code in the cell below. You have just two lines to complete. The goal is to use a large sample of the Reuters corpus to establish the extent to which vocabulary size is reduced when number and case normalisation is applied.\n",
    "- For each of the two incomplete lines you should ideally use nested list comprehensions. This is described in Section 5.1.4 in [this document](http://docs.python.org/tutorial/datastructures.html#list-comprehensions).  Alternatively, you could define functions which iterate over the sentences in each sample and the tokens within each sentence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JEtQ39z_nEGm",
    "outputId": "d5f2e4c8-21f4-461b-aa19-79262cd656ff"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     C:\\Users\\efemi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('reuters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VW4W9DfJpej7",
    "outputId": "f444236c-b28a-46fa-cda5-3158bc1cc84a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\efemi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qePwmgrnjXsk",
    "outputId": "3c999b76-4008-461a-feb0-faf22bff7e23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalisation produced a 28.25% reduction in vocabulary size from 20351 to 14601\n"
     ]
    }
   ],
   "source": [
    "#the sample_sentences() function from the last lab will be useful here\n",
    "#next week we will look at including useful functions like this in a utils python file which we can import from\n",
    "import random\n",
    "\n",
    "def sample_sentences(corpus,sample_size):\n",
    "\n",
    "    size=len(corpus)\n",
    "    ids=random.sample(range(size),sample_size)\n",
    "    sample=[corpus[i] for i in ids]\n",
    "    return sample\n",
    "\n",
    "#in vocabulary_size(), we use a dictionary to store the frequency of each token type in the corpus\n",
    "#the number of keys in this dictionary is the size of the vocab\n",
    "def vocabulary_size(sentences):\n",
    "    tok_counts = {}\n",
    "    for sentence in sentences:\n",
    "        for token in sentence:\n",
    "            tok_counts[token]=tok_counts.get(token,0)+1\n",
    "    return len(tok_counts.keys())\n",
    "\n",
    "\n",
    "\n",
    "sample_size = 10000\n",
    "\n",
    "raw_sentences = sample_sentences(reuters.sents(),sample_size)\n",
    "\n",
    "############################################\n",
    "lowered_sentences = [[token.lower() for token in sentence] for sentence in raw_sentences]\n",
    "normalised_sentences = [[\"Num\" if token.isdigit() or (token.endswith(('st', 'nd', 'rd', 'th')) and token[-2].isdigit()) else token for token in sentence] for sentence in lowered_sentences]\n",
    "\n",
    "############################################\n",
    "\n",
    "raw_vocab_size = vocabulary_size(raw_sentences)\n",
    "normalised_vocab_size = vocabulary_size(normalised_sentences)\n",
    "print(\"Normalisation produced a {0:.2f}% reduction in vocabulary size from {1} to {2}\".format(\n",
    "    100*(raw_vocab_size - normalised_vocab_size)/raw_vocab_size,raw_vocab_size,normalised_vocab_size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sXE01afsjXsq"
   },
   "source": [
    "## Stemming\n",
    "A considerable amount of the lexical variation found in documents results from the use of morphological variants which we might not wish to distinguish - e.g. when determining the topic of a document. An easy way to remove these varied forms is to use a stemmer. NLTK includes a number of stemmers in the `nltk.stem` package.\n",
    "- [NLTK stem module API](https://www.nltk.org/api/nltk.stem.html)\n",
    "\n",
    "- [NLTK Porter stemmer](https://www.nltk.org/api/nltk.stem.porter.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LYvUBOUnjXsr"
   },
   "source": [
    "- Look at the code below to show how the NLTK implementation of the Porter stemmer in `nltk.stem.porter.PorterStemmer` stems a sample of sentences in the Reuters corpus.\n",
    "- Have a close look at the differences between the columns. This will give you a good indication of what the stemmer does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "RLMKMiU3jXsr",
    "outputId": "833b2122-df1d-4be7-a698-6af8e0d7324a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEFORE</th>\n",
       "      <th>AFTER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Johnson</td>\n",
       "      <td>johnson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Geneva</td>\n",
       "      <td>geneva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>said</td>\n",
       "      <td>said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>buy</td>\n",
       "      <td>buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>out</td>\n",
       "      <td>out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>was</td>\n",
       "      <td>wa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>accomplished</td>\n",
       "      <td>accomplish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>through</td>\n",
       "      <td>through</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&amp;</td>\n",
       "      <td>&amp;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>lt</td>\n",
       "      <td>lt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>;</td>\n",
       "      <td>;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Onpraise</td>\n",
       "      <td>onprais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ltd</td>\n",
       "      <td>ltd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>&gt;,</td>\n",
       "      <td>&gt;,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Hong</td>\n",
       "      <td>hong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Kong</td>\n",
       "      <td>kong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>company</td>\n",
       "      <td>compani</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>controlled</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>by</td>\n",
       "      <td>by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Johnson</td>\n",
       "      <td>johnson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Geneva</td>\n",
       "      <td>geneva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Chairman</td>\n",
       "      <td>chairman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Michael</td>\n",
       "      <td>michael</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Johnson</td>\n",
       "      <td>johnson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          BEFORE       AFTER\n",
       "0        Johnson     johnson\n",
       "1         Geneva      geneva\n",
       "2           said        said\n",
       "3            the         the\n",
       "4            buy         buy\n",
       "5            out         out\n",
       "6            was          wa\n",
       "7   accomplished  accomplish\n",
       "8        through     through\n",
       "9              &           &\n",
       "10            lt          lt\n",
       "11             ;           ;\n",
       "12      Onpraise     onprais\n",
       "13           Ltd         ltd\n",
       "14            >,          >,\n",
       "15             a           a\n",
       "16          Hong        hong\n",
       "17          Kong        kong\n",
       "18       company     compani\n",
       "19    controlled     control\n",
       "20            by          by\n",
       "21       Johnson     johnson\n",
       "22        Geneva      geneva\n",
       "23      Chairman    chairman\n",
       "24       Michael     michael\n",
       "25       Johnson     johnson\n",
       "26             .           ."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEFORE</th>\n",
       "      <th>AFTER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"</td>\n",
       "      <td>\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sentiment</td>\n",
       "      <td>sentiment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>market</td>\n",
       "      <td>market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>is</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bullish</td>\n",
       "      <td>bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>think</td>\n",
       "      <td>think</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>it</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>will</td>\n",
       "      <td>will</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>continue</td>\n",
       "      <td>continu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>that</td>\n",
       "      <td>that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>way</td>\n",
       "      <td>way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>as</td>\n",
       "      <td>as</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>demand</td>\n",
       "      <td>demand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>will</td>\n",
       "      <td>will</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>go</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>up</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>third</td>\n",
       "      <td>third</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>or</td>\n",
       "      <td>or</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>fourth</td>\n",
       "      <td>fourth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>quarters</td>\n",
       "      <td>quarter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>,\"</td>\n",
       "      <td>,\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Subroto</td>\n",
       "      <td>subroto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>said</td>\n",
       "      <td>said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       BEFORE      AFTER\n",
       "0           \"          \"\n",
       "1         The        the\n",
       "2   sentiment  sentiment\n",
       "3          in         in\n",
       "4         the        the\n",
       "5      market     market\n",
       "6          is         is\n",
       "7     bullish    bullish\n",
       "8         and        and\n",
       "9           I          i\n",
       "10      think      think\n",
       "11         it         it\n",
       "12       will       will\n",
       "13   continue    continu\n",
       "14       that       that\n",
       "15        way        way\n",
       "16         as         as\n",
       "17     demand     demand\n",
       "18       will       will\n",
       "19         go         go\n",
       "20         up         up\n",
       "21         in         in\n",
       "22        the        the\n",
       "23      third      third\n",
       "24         or         or\n",
       "25     fourth     fourth\n",
       "26   quarters    quarter\n",
       "27         ,\"         ,\"\n",
       "28    Subroto    subroto\n",
       "29       said       said\n",
       "30          .          ."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEFORE</th>\n",
       "      <th>AFTER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PHLCORP</td>\n",
       "      <td>phlcorp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&amp;</td>\n",
       "      <td>&amp;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lt</td>\n",
       "      <td>lt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>;</td>\n",
       "      <td>;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PHX</td>\n",
       "      <td>phx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>dlrs</td>\n",
       "      <td>dlr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>tax</td>\n",
       "      <td>tax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>credits</td>\n",
       "      <td>credit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     BEFORE    AFTER\n",
       "0   PHLCORP  phlcorp\n",
       "1         &        &\n",
       "2        lt       lt\n",
       "3         ;        ;\n",
       "4       PHX      phx\n",
       "..      ...      ...\n",
       "61     dlrs      dlr\n",
       "62       in       in\n",
       "63      tax      tax\n",
       "64  credits   credit\n",
       "65        .        .\n",
       "\n",
       "[66 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEFORE</th>\n",
       "      <th>AFTER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IPCO</td>\n",
       "      <td>ipco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CORP</td>\n",
       "      <td>corp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&amp;</td>\n",
       "      <td>&amp;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lt</td>\n",
       "      <td>lt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>;</td>\n",
       "      <td>;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>IHS</td>\n",
       "      <td>ih</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&gt;</td>\n",
       "      <td>&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SETS</td>\n",
       "      <td>set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>REGULAR</td>\n",
       "      <td>regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PAYOUT</td>\n",
       "      <td>payout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Qtrly</td>\n",
       "      <td>qtrli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>div</td>\n",
       "      <td>div</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>nine</td>\n",
       "      <td>nine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cts</td>\n",
       "      <td>ct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>vs</td>\n",
       "      <td>vs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>nine</td>\n",
       "      <td>nine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cts</td>\n",
       "      <td>ct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>prior</td>\n",
       "      <td>prior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Pay</td>\n",
       "      <td>pay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>May</td>\n",
       "      <td>may</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Record</td>\n",
       "      <td>record</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>April</td>\n",
       "      <td>april</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     BEFORE    AFTER\n",
       "0      IPCO     ipco\n",
       "1      CORP     corp\n",
       "2         &        &\n",
       "3        lt       lt\n",
       "4         ;        ;\n",
       "5       IHS       ih\n",
       "6         >        >\n",
       "7      SETS      set\n",
       "8   REGULAR  regular\n",
       "9    PAYOUT   payout\n",
       "10    Qtrly    qtrli\n",
       "11      div      div\n",
       "12     nine     nine\n",
       "13      cts       ct\n",
       "14       vs       vs\n",
       "15     nine     nine\n",
       "16      cts       ct\n",
       "17    prior    prior\n",
       "18      Pay      pay\n",
       "19      May      may\n",
       "20        1        1\n",
       "21   Record   record\n",
       "22    April    april\n",
       "23        9        9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEFORE</th>\n",
       "      <th>AFTER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Low</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yields</td>\n",
       "      <td>yield</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>from</td>\n",
       "      <td>from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>country</td>\n",
       "      <td>countri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>'</td>\n",
       "      <td>'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ageing</td>\n",
       "      <td>age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>coffee</td>\n",
       "      <td>coffe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>plantations</td>\n",
       "      <td>plantat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>prevalence</td>\n",
       "      <td>preval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fungal</td>\n",
       "      <td>fungal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>disease</td>\n",
       "      <td>diseas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Hemileia</td>\n",
       "      <td>hemileia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Vastatrix</td>\n",
       "      <td>vastatrix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>also</td>\n",
       "      <td>also</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>contributed</td>\n",
       "      <td>contribut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>poor</td>\n",
       "      <td>poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>performance</td>\n",
       "      <td>perform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sources</td>\n",
       "      <td>sourc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>said</td>\n",
       "      <td>said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         BEFORE      AFTER\n",
       "0           Low        low\n",
       "1        yields      yield\n",
       "2          from       from\n",
       "3           the        the\n",
       "4       country    countri\n",
       "5             '          '\n",
       "6             s          s\n",
       "7        ageing        age\n",
       "8        coffee      coffe\n",
       "9   plantations    plantat\n",
       "10          and        and\n",
       "11   prevalence     preval\n",
       "12           of         of\n",
       "13          the        the\n",
       "14       fungal     fungal\n",
       "15      disease     diseas\n",
       "16     Hemileia   hemileia\n",
       "17    Vastatrix  vastatrix\n",
       "18         also       also\n",
       "19  contributed  contribut\n",
       "20           to         to\n",
       "21          the        the\n",
       "22         poor       poor\n",
       "23  performance    perform\n",
       "24            ,          ,\n",
       "25          the        the\n",
       "26      sources      sourc\n",
       "27         said       said\n",
       "28            .          ."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEFORE</th>\n",
       "      <th>AFTER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRITAIN</td>\n",
       "      <td>britain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CALLS</td>\n",
       "      <td>call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ON</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JAPAN</td>\n",
       "      <td>japan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TO</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>INCREASE</td>\n",
       "      <td>increas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>IMPORTS</td>\n",
       "      <td>import</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Britain</td>\n",
       "      <td>britain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>today</td>\n",
       "      <td>today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>called</td>\n",
       "      <td>call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>on</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Japan</td>\n",
       "      <td>japan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>increase</td>\n",
       "      <td>increas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>foreign</td>\n",
       "      <td>foreign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>imports</td>\n",
       "      <td>import</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>or</td>\n",
       "      <td>or</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>risk</td>\n",
       "      <td>risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>rise</td>\n",
       "      <td>rise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>protectionism</td>\n",
       "      <td>protection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>harm</td>\n",
       "      <td>harm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>it</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>would</td>\n",
       "      <td>would</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>bring</td>\n",
       "      <td>bring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>it</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>trading</td>\n",
       "      <td>trade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>nations</td>\n",
       "      <td>nation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           BEFORE       AFTER\n",
       "0         BRITAIN     britain\n",
       "1           CALLS        call\n",
       "2              ON          on\n",
       "3           JAPAN       japan\n",
       "4              TO          to\n",
       "5        INCREASE     increas\n",
       "6         IMPORTS      import\n",
       "7         Britain     britain\n",
       "8           today       today\n",
       "9          called        call\n",
       "10             on          on\n",
       "11          Japan       japan\n",
       "12             to          to\n",
       "13       increase     increas\n",
       "14        foreign     foreign\n",
       "15        imports      import\n",
       "16             or          or\n",
       "17           risk        risk\n",
       "18            the         the\n",
       "19           rise        rise\n",
       "20             of          of\n",
       "21  protectionism  protection\n",
       "22            and         and\n",
       "23            the         the\n",
       "24           harm        harm\n",
       "25             it          it\n",
       "26          would       would\n",
       "27          bring       bring\n",
       "28             to          to\n",
       "29             it          it\n",
       "30            and         and\n",
       "31          other       other\n",
       "32        trading       trade\n",
       "33        nations      nation\n",
       "34              .           ."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEFORE</th>\n",
       "      <th>AFTER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USAir</td>\n",
       "      <td>usair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>was</td>\n",
       "      <td>wa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>halted</td>\n",
       "      <td>halt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>on</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>New</td>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>York</td>\n",
       "      <td>york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Stock</td>\n",
       "      <td>stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EXcahnge</td>\n",
       "      <td>excahng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>for</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dissemination</td>\n",
       "      <td>dissemin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>news</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           BEFORE     AFTER\n",
       "0           USAir     usair\n",
       "1             was        wa\n",
       "2          halted      halt\n",
       "3              on        on\n",
       "4             the       the\n",
       "5             New       new\n",
       "6            York      york\n",
       "7           Stock     stock\n",
       "8        EXcahnge   excahng\n",
       "9             for       for\n",
       "10  dissemination  dissemin\n",
       "11             of        of\n",
       "12            the       the\n",
       "13           news      news\n",
       "14              .         ."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEFORE</th>\n",
       "      <th>AFTER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>said</td>\n",
       "      <td>said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>debt</td>\n",
       "      <td>debt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>was</td>\n",
       "      <td>wa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>part</td>\n",
       "      <td>part</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>billion</td>\n",
       "      <td>billion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>franc</td>\n",
       "      <td>franc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>liability</td>\n",
       "      <td>liabil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>incurred</td>\n",
       "      <td>incur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>through</td>\n",
       "      <td>through</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>activation</td>\n",
       "      <td>activ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>EMCF</td>\n",
       "      <td>emcf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>swap</td>\n",
       "      <td>swap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>facilities</td>\n",
       "      <td>facil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>defend</td>\n",
       "      <td>defend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>franc</td>\n",
       "      <td>franc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>before</td>\n",
       "      <td>befor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>January</td>\n",
       "      <td>januari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>European</td>\n",
       "      <td>european</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Monetary</td>\n",
       "      <td>monetari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>System</td>\n",
       "      <td>system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>realignment</td>\n",
       "      <td>realign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         BEFORE     AFTER\n",
       "0            It        it\n",
       "1          said      said\n",
       "2           the       the\n",
       "3          debt      debt\n",
       "4           was        wa\n",
       "5          part      part\n",
       "6            of        of\n",
       "7             a         a\n",
       "8            33        33\n",
       "9             .         .\n",
       "10           90        90\n",
       "11      billion   billion\n",
       "12        franc     franc\n",
       "13    liability    liabil\n",
       "14     incurred     incur\n",
       "15      through   through\n",
       "16          the       the\n",
       "17   activation     activ\n",
       "18           of        of\n",
       "19         EMCF      emcf\n",
       "20         swap      swap\n",
       "21   facilities     facil\n",
       "22           to        to\n",
       "23       defend    defend\n",
       "24          the       the\n",
       "25        franc     franc\n",
       "26       before     befor\n",
       "27          the       the\n",
       "28      January   januari\n",
       "29           11        11\n",
       "30     European  european\n",
       "31     Monetary  monetari\n",
       "32       System    system\n",
       "33  realignment   realign\n",
       "34            .         ."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEFORE</th>\n",
       "      <th>AFTER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crop</td>\n",
       "      <td>crop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>reporting</td>\n",
       "      <td>report</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>board</td>\n",
       "      <td>board</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>said</td>\n",
       "      <td>said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>estimates</td>\n",
       "      <td>estim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>for</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1986</td>\n",
       "      <td>1986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/</td>\n",
       "      <td>/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>season</td>\n",
       "      <td>season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>are</td>\n",
       "      <td>are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>based</td>\n",
       "      <td>base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>on</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>maturity</td>\n",
       "      <td>matur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>yields</td>\n",
       "      <td>yield</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tests</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>as</td>\n",
       "      <td>as</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>March</td>\n",
       "      <td>march</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       BEFORE   AFTER\n",
       "0         The     the\n",
       "1        crop    crop\n",
       "2   reporting  report\n",
       "3       board   board\n",
       "4        said    said\n",
       "5         the     the\n",
       "6   estimates   estim\n",
       "7         for     for\n",
       "8         the     the\n",
       "9        1986    1986\n",
       "10          /       /\n",
       "11         87      87\n",
       "12     season  season\n",
       "13        are     are\n",
       "14      based    base\n",
       "15         on      on\n",
       "16   maturity   matur\n",
       "17        and     and\n",
       "18     yields   yield\n",
       "19      tests    test\n",
       "20         as      as\n",
       "21         of      of\n",
       "22      March   march\n",
       "23          1       1\n",
       "24          .       ."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEFORE</th>\n",
       "      <th>AFTER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1986</td>\n",
       "      <td>1986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4th</td>\n",
       "      <td>4th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qtr</td>\n",
       "      <td>qtr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>includes</td>\n",
       "      <td>includ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mln</td>\n",
       "      <td>mln</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dlr</td>\n",
       "      <td>dlr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>provision</td>\n",
       "      <td>provis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>for</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>costs</td>\n",
       "      <td>cost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>anticipated</td>\n",
       "      <td>anticip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>connection</td>\n",
       "      <td>connect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>with</td>\n",
       "      <td>with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>disposal</td>\n",
       "      <td>dispos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>division</td>\n",
       "      <td>divis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>000</td>\n",
       "      <td>000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>dlrs</td>\n",
       "      <td>dlr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>adjustments</td>\n",
       "      <td>adjust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>related</td>\n",
       "      <td>relat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>write</td>\n",
       "      <td>write</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>downs</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         BEFORE    AFTER\n",
       "0          1986     1986\n",
       "1           4th      4th\n",
       "2           qtr      qtr\n",
       "3      includes   includ\n",
       "4             3        3\n",
       "5             .        .\n",
       "6             5        5\n",
       "7           mln      mln\n",
       "8           dlr      dlr\n",
       "9     provision   provis\n",
       "10          for      for\n",
       "11        costs     cost\n",
       "12  anticipated  anticip\n",
       "13           in       in\n",
       "14   connection  connect\n",
       "15         with     with\n",
       "16     disposal   dispos\n",
       "17           of       of\n",
       "18     division    divis\n",
       "19          and      and\n",
       "20          500      500\n",
       "21            ,        ,\n",
       "22          000      000\n",
       "23         dlrs      dlr\n",
       "24           in       in\n",
       "25  adjustments   adjust\n",
       "26      related    relat\n",
       "27           to       to\n",
       "28        write    write\n",
       "29            -        -\n",
       "30        downs     down\n",
       "31            .        ."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "st = PorterStemmer()\n",
    "\n",
    "sample_size = 10\n",
    "\n",
    "tokenised_sentences = sample_sentences(reuters.sents(),sample_size)\n",
    "\n",
    "for sentence in tokenised_sentences:\n",
    "    df = pd.DataFrame(list(zip_longest(sentence,[st.stem(token) for token in sentence])),columns=[\"BEFORE\",\"AFTER\"])\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZaBir7EVjXsw"
   },
   "source": [
    "### Exercise 2.1\n",
    "- By looking at the impact on a large sample of the Reuters corpus, establish the extent to which vocabulary size is reduced by stemming.\n",
    "- Write code to do this in the empty cell below. You should be able to re-use a lot of the code from the code you used when measuring the impact of lower case and number normalisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "laXsH-MZjXsx",
    "outputId": "6b95cebb-9793-4009-88a9-f24b19dc3235"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemming produced a 47.30% reduction in vocabulary size from 20208 to 10649\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def sample_sentences(corpus,sample_size):\n",
    "\n",
    "    size=len(corpus)\n",
    "    ids=random.sample(range(size),sample_size)\n",
    "    sample=[corpus[i] for i in ids]\n",
    "    return sample\n",
    "\n",
    "#in vocabulary_size(), we use a dictionary to store the frequency of each token type in the corpus\n",
    "#the number of keys in this dictionary is the size of the vocab\n",
    "def vocabulary_size(sentences):\n",
    "    tok_counts = {}\n",
    "    for sentence in sentences:\n",
    "        for token in sentence:\n",
    "            tok_counts[token]=tok_counts.get(token,0)+1\n",
    "    return len(tok_counts.keys())\n",
    "\n",
    "\n",
    "\n",
    "sample_size = 10000\n",
    "\n",
    "raw_sentences = sample_sentences(reuters.sents(),sample_size)\n",
    "\n",
    "############################################\n",
    "normalised_sentences=[number_normalise(sentence) for sentence in raw_sentences]\n",
    "stem_sentences = [[st.stem(token) for token in sentence] for sentence in normalised_sentences]\n",
    "\n",
    "\n",
    "############################################\n",
    "\n",
    "raw_vocab_size = vocabulary_size(raw_sentences)\n",
    "stem_vocab_size = vocabulary_size(stem_sentences)\n",
    "print(\"Stemming produced a {0:.2f}% reduction in vocabulary size from {1} to {2}\".format(\n",
    "    100*(raw_vocab_size - stem_vocab_size)/raw_vocab_size,raw_vocab_size,stem_vocab_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZzA9Cl6ZjXsz"
   },
   "source": [
    "### Exercise 2.2\n",
    "* Try using the WordNetLemmatizer <code>nltk.stem.wordnet.WordNetLemmatizer</code> instead of the Porter Stemmer.\n",
    "* Using a large sample of the Reuters corpus, establish the extent to which the vocabulary size reduced by lemmatization?\n",
    "* As an extension, you could look at different sample sizes and/or different corpora and display the results in a table or graph (e.g., using <code>pandas</code> and/or <code>matplotlib</code>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9p26OMMZS34I",
    "outputId": "090a517f-c486-4b23-c0c0-00ac06f4049b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\efemi\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NBLtSKiimwG9",
    "outputId": "4f5363fd-1cd5-4540-aafd-5dc890465bbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalisation produced a 11.45% reduction in vocabulary size from 20153 to 17846\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import random\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "def sample_sentences(corpus,sample_size):\n",
    "\n",
    "    size=len(corpus)\n",
    "    ids=random.sample(range(size),sample_size)\n",
    "    sample=[corpus[i] for i in ids]\n",
    "    return sample\n",
    "\n",
    "#in vocabulary_size(), we use a dictionary to store the frequency of each token type in the corpus\n",
    "#the number of keys in this dictionary is the size of the vocab\n",
    "def vocabulary_size(sentences):\n",
    "    tok_counts = {}\n",
    "    for sentence in sentences:\n",
    "        for token in sentence:\n",
    "            tok_counts[token]=tok_counts.get(token,0)+1\n",
    "    return len(tok_counts.keys())\n",
    "\n",
    "\n",
    "\n",
    "sample_size = 10000\n",
    "\n",
    "raw_sentences = sample_sentences(reuters.sents(),sample_size)\n",
    "\n",
    "############################################\n",
    "normalised_sentences=[number_normalise(sentence) for sentence in raw_sentences]\n",
    "lemma_sentences = [[wnl.lemmatize(token) for token in sentence] for sentence in normalised_sentences]\n",
    "\n",
    "\n",
    "############################################\n",
    "\n",
    "raw_vocab_size = vocabulary_size(raw_sentences)\n",
    "lemma_vocab_size = vocabulary_size(lemma_sentences)\n",
    "print(\"Normalisation produced a {0:.2f}% reduction in vocabulary size from {1} to {2}\".format(\n",
    "    100*(raw_vocab_size - lemma_vocab_size)/raw_vocab_size,raw_vocab_size,lemma_vocab_size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kBwfUlC3jXs1"
   },
   "source": [
    "### Punctuation and stop-word removal\n",
    "A stopword is a word that occurs so often that it loses its usefulness in some tasks. We may get more meaningful information from our corpus analysis if we remove stopwords and punctuation.\n",
    "\n",
    "The code below takes a list of tokens and creates a new list, which contains only those strings which are alphabetic and non-stop-words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2suL2eJOmqvW",
    "outputId": "32d99f18-1647-4417-c0a3-7e5c46189a7c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\efemi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mhTSVWNcjXs2",
    "outputId": "1d8abdcf-1d6d-4851-a348-7c2e3371032e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'cat', ',', 'which', 'is', 'really', 'fat', ',', 'sat', 'on', 'the', 'mat']\n",
      "['cat', 'really', 'fat', 'sat', 'mat']\n"
     ]
    }
   ],
   "source": [
    "stop = stopwords.words('english')\n",
    "tokens=\"The cat , which is really fat , sat on the mat\".lower().split()\n",
    "filtered_tokens = [w for w in tokens if w.isalpha() and w not in stop]\n",
    "print(tokens)\n",
    "print(filtered_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QGATIwNmjXs5"
   },
   "source": [
    "**Note**: `isalpha` only returns `True` if the string is entirely composed of alphabet characters. If you want a function to return `True` even when a word contains digits, then you should use `isalnum`.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_XyRZmVnjXs5"
   },
   "source": [
    "### Exercise 3.1\n",
    "- In the empty cell below, write code that looks at a large sample of the Reuters corpus, establishing what proportion of tokens are stop-words.\n",
    "- As extension, you could establish the mean (and or the distribution of the) number of stop-words per sentence; or compare the numbers of stop-words in different corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "scuIYe_xjXs6",
    "outputId": "92391e91-e447-4131-90e1-e14a636e4e87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['It',\n",
       "  'said',\n",
       "  'might',\n",
       "  'take',\n",
       "  'legal',\n",
       "  'action',\n",
       "  'seek',\n",
       "  'support',\n",
       "  'shareholder',\n",
       "  'calling',\n",
       "  'special',\n",
       "  'meeting',\n",
       "  'replace',\n",
       "  'board',\n",
       "  'consider',\n",
       "  'proposal'],\n",
       " ['A',\n",
       "  'high',\n",
       "  'command',\n",
       "  'communique',\n",
       "  'said',\n",
       "  'warplane',\n",
       "  'hit',\n",
       "  'western',\n",
       "  'jetty',\n",
       "  'Iran',\n",
       "  'Kharg',\n",
       "  'island',\n",
       "  'oil',\n",
       "  'terminal',\n",
       "  'afternoon',\n",
       "  'struck',\n",
       "  'supertanker',\n",
       "  'nearby',\n",
       "  'time'],\n",
       " ['As',\n",
       "  'result',\n",
       "  'net',\n",
       "  'income',\n",
       "  'first',\n",
       "  'quarter',\n",
       "  'reduced',\n",
       "  'NUM',\n",
       "  'mln',\n",
       "  'dlrs'],\n",
       " ['CORN',\n",
       "  'SOYBEANS',\n",
       "  'TOLEDO',\n",
       "  'NUM',\n",
       "  'UND',\n",
       "  'MAY',\n",
       "  'UNC',\n",
       "  'NUM',\n",
       "  'UND',\n",
       "  'MAY',\n",
       "  'UNC',\n",
       "  'CINCINNATI',\n",
       "  'NUM',\n",
       "  'UND',\n",
       "  'MAY',\n",
       "  'UNC',\n",
       "  'NUM',\n",
       "  'OVR',\n",
       "  'MAY',\n",
       "  'UP',\n",
       "  'NUM',\n",
       "  'NEW',\n",
       "  'HAVEN',\n",
       "  'NUM',\n",
       "  'UND',\n",
       "  'MAY',\n",
       "  'UNC',\n",
       "  'NUM',\n",
       "  'UND',\n",
       "  'MAY',\n",
       "  'DN',\n",
       "  'NUM',\n",
       "  'N',\n",
       "  'E'],\n",
       " ['The',\n",
       "  'federal',\n",
       "  'government',\n",
       "  'drew',\n",
       "  'NUM',\n",
       "  'NUM',\n",
       "  'billion',\n",
       "  'mark',\n",
       "  'Bundesbank',\n",
       "  'cash',\n",
       "  'deposit',\n",
       "  'stood',\n",
       "  'NUM',\n",
       "  'NUM',\n",
       "  'billion',\n",
       "  'third',\n",
       "  'week',\n",
       "  'February',\n",
       "  'also',\n",
       "  'borrowed',\n",
       "  'NUM',\n",
       "  'NUM',\n",
       "  'billion',\n",
       "  'credit',\n",
       "  'central',\n",
       "  'bank']]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_size = 10000\n",
    "\n",
    "raw_sentences = sample_sentences(reuters.sents(),sample_size)\n",
    "\n",
    "normalised_sentences=[number_normalise(sentence) for sentence in raw_sentences]\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "lemma_sentences = [[wnl.lemmatize(token) for token in sentence] for sentence in normalised_sentences]\n",
    "\n",
    "stop_word_exc = [[w for w in sentence if w.isalpha() and w not in stop ] for sentence in lemma_sentences]\n",
    "stop_word_exc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IBqUhG8uV6x6",
    "outputId": "ea1f355f-6892-46b9-de82-9dd0629c7891"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315526\n",
      "73645\n"
     ]
    }
   ],
   "source": [
    "# As extension, you could establish the mean (and or the distribution of the) number of stop-words per sentence; or compare the numbers of stop-words in different corpora.\n",
    "number_token = 0\n",
    "number_stop = 0\n",
    "\n",
    "for sentence in lemma_sentences:\n",
    "  for token in sentence:\n",
    "    number_token +=1\n",
    "    if token in stop:\n",
    "        number_stop += 1\n",
    "\n",
    "print(number_token)\n",
    "print(number_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sUUOjqB9nRSp"
   },
   "source": [
    "### Exercise 3.2\n",
    "Explain the difference between the number of tokens in a corpus and the size of the vocabulary of a corpus.\n",
    "Would you expect stopword removal to have a greater effect on the size of the vocabulary or the number of tokens in the corpus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ba2ncBYZjXs9"
   },
   "outputs": [],
   "source": [
    "#### My answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z-ztBumkV01I"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
