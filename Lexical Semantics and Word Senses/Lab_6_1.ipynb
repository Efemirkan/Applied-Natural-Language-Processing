{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meI5qrz3x0WS"
      },
      "source": [
        "# Week 6 Lab: Lexical Semantics\n",
        "\n",
        "This week we turn our attention to lexical semantics, i.e., the meaning of words.  In this lab, you will be\n",
        "* exploring the WordNet resource\n",
        "* learning about lexical relations such as synonymy and hyponymy\n",
        "* quantifying semantic similarity via distance in the WordNet hierarchy\n",
        "* comparing WordNet similarity scores with human synonymy judgements\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9-TaPbgx0WU"
      },
      "outputs": [],
      "source": [
        "###uncomment if working on colab\n",
        "\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IT_oEZgEx0Wa"
      },
      "source": [
        "First, lets import WordNet from the nltk library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Sr0Q3HlPx0Wa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72800487-5c60-4c4e-b852-b66bc1104c15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet_ic.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('wordnet_ic')\n",
        "\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.corpus import wordnet_ic as wn_ic\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eRGZcKhx0Wh"
      },
      "source": [
        "## Navigating WordNet\n",
        "\n",
        "Central to the organisation of WordNet is the idea of a synset.  Words have senses and senses are grouped with synonymous senses (of other words) in **synsets**\n",
        "\n",
        "If you want to find out which synsets a word belongs to, you use the `synsets` function.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NB2PqZqbx0Wi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa30580e-6c0e-46ee-8ede-4841f9749b1b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('plant.n.01'),\n",
              " Synset('plant.n.02'),\n",
              " Synset('plant.n.03'),\n",
              " Synset('plant.n.04'),\n",
              " Synset('plant.v.01'),\n",
              " Synset('implant.v.01'),\n",
              " Synset('establish.v.02'),\n",
              " Synset('plant.v.04'),\n",
              " Synset('plant.v.05'),\n",
              " Synset('plant.v.06')]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "wn.synsets(\"plant\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfTgERxcx0Wn"
      },
      "source": [
        "The output is a list of `Synset` objects each of which has a unique identifier containing one of its words, its part of speech and a number.  `Synset('book.n.01')` is the first noun sense of *book*.  However the word book is also in `Synset('record.n.05')` which is the fifth noun sense of *record*.  Lets inspect this synset further."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "AhydtCxOx0Wo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bafad1f9-78f4-41bd-d9aa-38f0d28a4ca0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['record', 'record_book', 'book']\n",
            "a compilation of the known facts regarding something or someone\n",
            "[\"Al Smith used to say, `Let's look at the record'\", 'his name is in all the record books']\n"
          ]
        }
      ],
      "source": [
        "book_synsets=wn.synsets('book')\n",
        "\n",
        "recordn5=book_synsets[2]\n",
        "print(recordn5.lemma_names())  #get the words in the synset\n",
        "print(recordn5.definition())   #get the definition of the synset\n",
        "print(recordn5.examples())  #get examples of the words used in this sense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "a48-tn6wQI0U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d7994da-965d-4fa6-b198-6e650ef8a527"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:buildings for carrying on industrial labor\n",
            "2:(botany) a living organism lacking the power of locomotion\n",
            "3:an actor situated in the audience whose acting is rehearsed but seems spontaneous to the audience\n",
            "4:something planted secretly for discovery by another\n",
            "5:put or set (seeds, seedlings, or plants) into the ground\n",
            "6:fix or set securely or deeply\n",
            "7:set up or lay the groundwork for\n",
            "8:place into a river\n",
            "9:place something or someone in a certain position in order to secretly observe or deceive\n",
            "10:put firmly in the mind\n"
          ]
        }
      ],
      "source": [
        "plant_synsets=wn.synsets('plant')\n",
        "for i,s in enumerate(plant_synsets):\n",
        "    print(\"{}:{}\".format(i+1,s.definition()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7TXDt_tx0Ws"
      },
      "source": [
        "If you only want to find synsets associated with a particular part of speech of a word then you can give `synsets` an extra argument"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "5BoxPB5kx0Wt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bca1d2c-849b-4a08-bbe3-942cd381e211"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: ['red', 'reddish', 'ruddy', 'blood-red', 'carmine', 'cerise', 'cherry', 'cherry-red', 'crimson', 'ruby', 'ruby-red', 'scarlet']\n",
            "1: ['crimson', 'red', 'violent']\n",
            "2: ['crimson', 'red', 'reddened', 'red-faced', 'flushed']\n"
          ]
        }
      ],
      "source": [
        "#all of the WN POS tags\n",
        "parts_of_speech=[wn.NOUN,wn.VERB,wn.ADJ,wn.ADV]\n",
        "\n",
        "#print(wn.synsets(\"red\",parts_of_speech[0]))\n",
        "\n",
        "red_synset = wn.synsets(\"red\", parts_of_speech[2])\n",
        "for i,s in enumerate(red_synset):\n",
        "  print(f\"{i}: {s.lemma_names()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuCYGSbIx0Ww"
      },
      "source": [
        "### Exercise 1.1\n",
        "* Write code to compute the number of synsets of each part of speech (noun, verb, adjective and adverb) for each of the following words:- book, chicken, counter, twig, fast, plant\n",
        "* Store and display the information using a Pandas dataframe\n",
        "\n",
        "Hint: you could use a nested list comprehension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "_Gy3FClJQI0V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "c0aea5bf-58be-4576-b30f-6f2b724de800"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   book  chicken  twig  fast  plant\n",
              "n    11        4     1     1      4\n",
              "v     4        0     2     2      6\n",
              "a     0        1     0    10      0\n",
              "r     0        0     0     2      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-df95529f-e927-4b86-a981-da8c41023669\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>book</th>\n",
              "      <th>chicken</th>\n",
              "      <th>twig</th>\n",
              "      <th>fast</th>\n",
              "      <th>plant</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>n</th>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>v</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>a</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>r</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df95529f-e927-4b86-a981-da8c41023669')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-df95529f-e927-4b86-a981-da8c41023669 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-df95529f-e927-4b86-a981-da8c41023669');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0bb1dc37-b2e9-47ef-8a96-959a2fc0e262\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0bb1dc37-b2e9-47ef-8a96-959a2fc0e262')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0bb1dc37-b2e9-47ef-8a96-959a2fc0e262 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_42e7bd1b-555e-488c-8738-c83b0273f818\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_42e7bd1b-555e-488c-8738-c83b0273f818 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"book\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 0,\n        \"max\": 11,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          11,\n          4,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chicken\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          4,\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"twig\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fast\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"plant\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          4,\n          6,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from itertools import zip_longest\n",
        "\n",
        "book_synsets1 = { parts_of_speech[i] : len(wn.synsets(\"book\", s)) for i, s in enumerate(parts_of_speech)}\n",
        "chicken_synsets1 = { parts_of_speech[i] : len(wn.synsets(\"chicken\", s)) for i, s in enumerate(parts_of_speech)}\n",
        "twig_synsets1 = { parts_of_speech[i] : len(wn.synsets(\"twig\", s)) for i, s in enumerate(parts_of_speech)}\n",
        "fast_synsets1 = { parts_of_speech[i] : len(wn.synsets(\"fast\", s)) for i, s in enumerate(parts_of_speech)}\n",
        "plant_synsets1 = { parts_of_speech[i] : len(wn.synsets(\"plant\", s)) for i, s in enumerate(parts_of_speech)}\n",
        "\n",
        "df= pd.DataFrame(list(zip_longest(book_synsets1.values(),chicken_synsets1.values(), twig_synsets1.values(),fast_synsets1.values(),plant_synsets1.values())),\n",
        "                 index=book_synsets.keys(),\n",
        "                 columns=[\"book\", \"chicken\", \"twig\", \"fast\", \"plant\"])\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5W1JRbJGNEM"
      },
      "source": [
        "The `Synset` object has a `lemmas()` method which returns all of the lemmas / word senses which make up that synset.  Remember, it is one sense of each word which is considered as synonymous within the synset.  Not every sense of *plant* is considered synonymous with every sense of *works*.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "Iou2W6gUQI0W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4962390b-082a-45fc-cf43-45258443f2c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:[Lemma('plant.n.01.plant'), Lemma('plant.n.01.works'), Lemma('plant.n.01.industrial_plant')]\n",
            "1:[Lemma('plant.n.02.plant'), Lemma('plant.n.02.flora'), Lemma('plant.n.02.plant_life')]\n",
            "2:[Lemma('plant.n.03.plant')]\n",
            "3:[Lemma('plant.n.04.plant')]\n",
            "4:[Lemma('plant.v.01.plant'), Lemma('plant.v.01.set')]\n",
            "5:[Lemma('implant.v.01.implant'), Lemma('implant.v.01.engraft'), Lemma('implant.v.01.embed'), Lemma('implant.v.01.imbed'), Lemma('implant.v.01.plant')]\n",
            "6:[Lemma('establish.v.02.establish'), Lemma('establish.v.02.found'), Lemma('establish.v.02.plant'), Lemma('establish.v.02.constitute'), Lemma('establish.v.02.institute')]\n",
            "7:[Lemma('plant.v.04.plant')]\n",
            "8:[Lemma('plant.v.05.plant')]\n",
            "9:[Lemma('plant.v.06.plant'), Lemma('plant.v.06.implant')]\n"
          ]
        }
      ],
      "source": [
        "for i,s in enumerate(plant_synsets):\n",
        "    print(\"{}:{}\".format(i,s.lemmas()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyGzf7ngQI0W"
      },
      "source": [
        "Access the word form of a `Lemma` using its `names()` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "EkPgeFpgQI0W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f342631a-cbc7-400b-b524-738c36a70686"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:['cat', 'true_cat']\n",
            "\tfeline mammal usually having thick soft fur and no ability to roar: domestic cats; wildcats\n",
            "1:['guy', 'cat', 'hombre', 'bozo']\n",
            "\tan informal term for a youth or man\n",
            "2:['cat']\n",
            "\ta spiteful woman gossip\n",
            "3:['kat', 'khat', 'qat', 'quat', 'cat', 'Arabian_tea', 'African_tea']\n",
            "\tthe leaves of the shrub Catha edulis which are chewed like tobacco or used to make tea; has the effect of a euphoric stimulant\n",
            "4:[\"cat-o'-nine-tails\", 'cat']\n",
            "\ta whip with nine knotted cords\n",
            "5:['Caterpillar', 'cat']\n",
            "\ta large tracked vehicle that is propelled by two endless metal belts; frequently used for moving earth in construction and farm work\n",
            "6:['big_cat', 'cat']\n",
            "\tany of several large cats typically able to roar and living in the wild\n",
            "7:['computerized_tomography', 'computed_tomography', 'CT', 'computerized_axial_tomography', 'computed_axial_tomography', 'CAT']\n",
            "\ta method of examining body organs by scanning them with X rays and using a computer to construct a series of cross-sectional scans along a single axis\n"
          ]
        }
      ],
      "source": [
        "cat_synsets = wn.synsets(\"cat\",wn.NOUN)\n",
        "for i,s in enumerate(cat_synsets):\n",
        "    wordforms=[l.name() for l in s.lemmas()]\n",
        "    print(\"{}:{}\\n\\t{}\".format(i,wordforms,s.definition()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIZpPnrYx0W2"
      },
      "source": [
        "The `Synset` object also has `hyponyms` and `hypernyms` methods which return hyponym and hypernym synsets respectively.\n",
        "\n",
        "For example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "TuAnSX4qx0W2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "390d0f68-207d-4a08-b1cb-339d67842daa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('won-lost_record.n.01'), Synset('logbook.n.01'), Synset('card.n.08')]"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ],
      "source": [
        "#getting back the list of hyponym synsets for recordn5 (the 5th noun sense of record)\n",
        "recordn5.hyponyms()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "Jmv7T0MvQI0X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "561c7dd2-8272-440b-f64d-357dd2826d85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['leopard', 'Panthera_pardus']:large feline of African and Asian forests usually having a tawny coat with black spots\n",
            "['snow_leopard', 'ounce', 'Panthera_uncia']:large feline of upland central Asia having long thick whitish fur\n",
            "['liger']:offspring of a male lion and a female tiger\n",
            "['lion', 'king_of_beasts', 'Panthera_leo']:large gregarious predatory feline of Africa and India having a tawny coat with a shaggy mane in the male\n",
            "['saber-toothed_tiger', 'sabertooth']:any of many extinct cats of the Old and New Worlds having long swordlike upper canine teeth; from the Oligocene through the Pleistocene\n",
            "['cheetah', 'chetah', 'Acinonyx_jubatus']:long-legged spotted cat of Africa and southwestern Asia having nonretractile claws; the swiftest mammal; can be trained to run down game\n",
            "['tiglon', 'tigon']:offspring of a male tiger and a female lion\n",
            "['tiger', 'Panthera_tigris']:large feline of forests in most of Asia having a tawny coat with black stripes; endangered\n",
            "['jaguar', 'panther', 'Panthera_onca', 'Felis_onca']:a large spotted feline of tropical America similar to the leopard; in some classifications considered a member of the genus Felis\n"
          ]
        }
      ],
      "source": [
        "#iterating over the hyponyms of the 6th Synset in the list of synsets for cat\n",
        "for h in cat_synsets[6].hyponyms():\n",
        "    h_words=[w.name() for w in h.lemmas()]\n",
        "    print(\"{}:{}\".format(h_words,h.definition()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "7TwIcn1nQI0Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5e5f419-e5c2-4238-e802-87ae30fff796"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['feline', 'felid']:any of various lithe-bodied roundheaded fissiped mammals, many with retractile claws\n"
          ]
        }
      ],
      "source": [
        "##Iterating over the hypernyms of the 6th sense of cat and output lemma names and definition\n",
        "for h in cat_synsets[6].hypernyms():\n",
        "    h_words=[w.name() for w in h.lemmas()]\n",
        "    print(\"{}:{}\".format(h_words,h.definition()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6C4qUDQQI0Y"
      },
      "source": [
        "As an alternative to calling .names() on the Lemmas associated with a Synset, you can also use the .lemma_names() method directly on a synset."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "book_synsets"
      ],
      "metadata": {
        "id": "vHvHQrXpcUpZ",
        "outputId": "d7917e6a-80d1-4348-9737-f78a7ccde282",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('book.n.01'),\n",
              " Synset('book.n.02'),\n",
              " Synset('record.n.05'),\n",
              " Synset('script.n.01'),\n",
              " Synset('ledger.n.01'),\n",
              " Synset('book.n.06'),\n",
              " Synset('book.n.07'),\n",
              " Synset('koran.n.01'),\n",
              " Synset('bible.n.01'),\n",
              " Synset('book.n.10'),\n",
              " Synset('book.n.11'),\n",
              " Synset('book.v.01'),\n",
              " Synset('reserve.v.04'),\n",
              " Synset('book.v.03'),\n",
              " Synset('book.v.04')]"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "luB2TjF6x0W5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2baf98a9-5b30-4907-9311-0113a4285837"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fact']\n"
          ]
        }
      ],
      "source": [
        "#recordn5=book_synsets[2]\n",
        "\n",
        "for h in recordn5.hypernyms():\n",
        "    print(h.lemma_names())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CudFnfA_x0W8"
      },
      "source": [
        "Since the hyponymy relation forms a tree, we would expect synsets to generally have multiple hyponyms and a single hypernym.  At the top of the tree (also called the **root**), the hypernym list will be empty.  Most noun concepts in WordNet share a common root hypernym which is *entity*.  At the bottom of the tree (also referred to as the **leaves** of the tree), the hyponym list will be empty"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWssYf-Gx0W9"
      },
      "source": [
        "### Exercise 1.2\n",
        "Write a function, `distance_to_root` that will take a Synset and traverse up the tree until it reaches a root of the tree.  When it does so, it should return the number of steps taken.\n",
        "\n",
        "Hint: This can be done using **recursion**, where a function repeatedly calls itself.  You need to define:\n",
        "* a base case:  How will the function know when it is at the top of the tree and what should it return?\n",
        "* a recursive step: In the general case, the function should call itself with a simpler problem (a Synset which is closer to the top of the tree).  When it gets the result of this function call, it needs to modify it in some way and then return its own answer\n",
        "\n",
        "Make sure you test your function.  You should find that the 5th noun sense of record is 6 steps from the top.\n",
        "\n",
        "How far are all of the other noun sense of book from a root of the tree?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_L-uMmbQI0Z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zyRTqZgx0XI"
      },
      "source": [
        "## Semantic Similarity in WordNet\n",
        "\n",
        "The simplest way of defining how similar two concepts are according to WordNet is to use the pathlength measure:\n",
        "\n",
        "\\begin{eqnarray*}\n",
        "\\mbox{sim}(\\mbox{synsetA},\\mbox{synsetB})=\\frac{1}{1+\\mbox{lengthOfPath}(\\mbox{synsetA},\\mbox{synsetB})}\n",
        "\\end{eqnarray*}\n",
        "\n",
        "We have also introduced other measures in the lectures which incorporate **information content**, i.e., the amount of information we receive when a word from a given synset is used (there is more information in being told that something is a *poodle* than in being told it is an *animal*).\n",
        "\n",
        "The `nltk.wn` module has built-in functions for computing these similarities between synsets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7IOQRN9x0XJ"
      },
      "outputs": [],
      "source": [
        "books=wn.synsets(\"book\",wn.NOUN)\n",
        "print(\"path_similarity {}\".format(wn.path_similarity(books[0],books[1])))\n",
        "\n",
        "brown_ic=wn_ic.ic(\"ic-brown.dat\")  #this gets information content data from the Brown corpus\n",
        "print(\"resnik_similarity {}\".format(wn.res_similarity(books[0],books[1],brown_ic)))\n",
        "print(\"lin_similarity {}\".format(wn.lin_similarity(books[0],books[1],brown_ic)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_KGE06Tx0XM"
      },
      "source": [
        "Note it is impossible to compare synsets of different parts of speech using these methods because they are not connected via hyponymy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9c7H_Qdx0XN"
      },
      "outputs": [],
      "source": [
        "booksN=wn.synsets(\"book\",wn.NOUN)\n",
        "booksV=wn.synsets(\"book\",wn.VERB)\n",
        "print(\"path_similarity {}\".format(wn.path_similarity(booksN[0],booksV[1])))\n",
        "print(\"resnik_similarity {}\".format(wn.res_similarity(booksN[0],booksV[1],brown_ic)))\n",
        "print(\"lin_similarity {}\".format(wn.lin_similarity(booksN[0],booksV[1],brown_ic)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OZSCQQZx0XP"
      },
      "source": [
        "### Exercise 2.1\n",
        "\n",
        "The similarity of two **words** with a given part of speech is defined as the **maximum** similarity of all possible sense pairings.  If word A has 5 noun senses and word B has 4 noun senses than there are 20 possible sense pairings to check.\n",
        "\n",
        "* Write a function which will compute the path_similarity of two nouns.\n",
        "* Make sure you test it.  The correct answer for *chicken* and *car* is 0.0909 to 3SF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHapYwDzQI0a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9PDsl7vx0XT"
      },
      "source": [
        "### Exercise 2.2\n",
        "Generalise your path_similarity function so that it takes an extra optional argument:\n",
        "* the similarity measure to use\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DP5v2eP8QI0a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVYBNfT_x0XX"
      },
      "outputs": [],
      "source": [
        "word_similarity(\"chicken\",\"car\",measure=\"lin\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OJGUbmwx0Xa"
      },
      "source": [
        "## Comparing WordNet Similarities with Human Synonymy Judgements\n",
        "\n",
        "The file `mcdata.csv` contains human synonymy judgements for a list of 30 noun pairs.   We can read in a `.csv` file using the `csv` library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKC0iTVOx0Xb"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import os\n",
        "directory='/content/drive/My Drive/NLE Notebooks/Week5LabsSolutions/'\n",
        "filename='mcdata.csv'\n",
        "filepath=os.path.join(directory,filename)\n",
        "\n",
        "\n",
        "with open(filename,'r') as filestream:\n",
        "    mcdata=list(csv.reader(filestream,delimiter=','))\n",
        "\n",
        "df=pd.DataFrame(mcdata,columns=[\"word1\",\"word2\",\"human similarity\"])\n",
        "#lets make sure the scores are floats not strings.  We can do this by applying the float() function to every value in the column (which we can using map)\n",
        "df[\"human similarity\"]=df[\"human similarity\"].map(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6U46J1KQI0b"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YdzQ023x0Xe"
      },
      "source": [
        "Note that the human similarity judgements range between 0 and 4.\n",
        "\n",
        "### Exercise 3.1\n",
        "Write code that will\n",
        "* compute the WordNet path_similarity for every pair of words in this data; and\n",
        "* add it as a column in the dataframe.  If you have the path similarity scores in a list called `scores`, you can do this using `df['path']=scores`\n",
        "\n",
        "Repeat for the Resnik and Lin similarity scores.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_gDyxWsQI0b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YVoa9A7x0Xk"
      },
      "source": [
        "We can use pandas functionality to produce scatter plots and examine the correlation between different variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUJzNFiqx0Xl"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "x=\"human similarity\"\n",
        "y=\"path\"\n",
        "\n",
        "df.plot.scatter(x,y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlFZwzqjx0Xp"
      },
      "source": [
        "### Exercise 3.2\n",
        "Generate scatter plots showing Resnik similarity against human similarity and Lin similarity against human similarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4GNQpTeQI0c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fV8PTmO-QI0c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-GNK8DAx0X7"
      },
      "source": [
        "The `DataFrame.corr()` method will compute the correlation for all pairs of columns with numeric values.  It is better to use Spearman's rank correlation coefficient than Pearson's product-moment correlation coefficient, since similarity scores are unlikely to be normally distributed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NAOCoUOx0X8"
      },
      "outputs": [],
      "source": [
        "df.corr(method='spearman')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORzNGby0x0YH"
      },
      "source": [
        "### Exercise 3.3\n",
        "* Looking at the scatter plots and the correlation coefficients, what do you conclude about the different WordNet similarity measures?\n",
        "* Do you have any reservations about your conclusions?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Wbpkgtbx0YJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}