{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swLDp-GV7iQg"
      },
      "source": [
        "# Week 3: Basic Document Classification (Part 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLh_fS4P7iQn"
      },
      "source": [
        "## Overview\n",
        "In labs this week (and next), the focus will be on the application of sentiment analysis. You will be using a corpus of **movie reviews**.\n",
        "\n",
        "You will be exploring various techniques that can be used to classify the sentiment of the movie reviews as either positive or negative.\n",
        "\n",
        "You will be developing your own **Word List** and **Naïve Bayes** classifiers and then comparing them to the **NLTK Naïve Bayes** classifier.\n",
        "\n",
        "First, we will need to download the movie_review corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3W2AdikDqe5G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af866ed0-139b-4c14-9924-4c148691795c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('movie_reviews')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0uVSM40qe5I"
      },
      "source": [
        "The movie_reviews corpus reader provides a number of useful methods:\n",
        "   * .categories()\n",
        "   * .fileids()\n",
        "   * .words()\n",
        "   \n",
        "First, we can use `.categories()` to check the set of labels with which the reviews have been labelled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "N3bRgahNqe5J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ccba9ba-dafa-49cc-a8cd-fe02089f131b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['neg', 'pos']\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import movie_reviews\n",
        "\n",
        "print(movie_reviews.categories())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INtoThcCqe5J"
      },
      "source": [
        "We can use `.fileids()` to get all of the file names associated with a particular category."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LZ00H5mdqe5K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c12538d5-aedc-43ab-bfd4-25f6fefb0f65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of positive reviews is 1000\n",
            "The number of negative reviews is 1000\n"
          ]
        }
      ],
      "source": [
        "pos_review_ids=movie_reviews.fileids('pos')\n",
        "neg_review_ids=movie_reviews.fileids('neg')\n",
        "\n",
        "print(\"The number of positive reviews is {}\".format(len(pos_review_ids)))\n",
        "print(\"The number of negative reviews is {}\".format(len(neg_review_ids)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoHxpQ6Sqe5L"
      },
      "source": [
        "We can use `.words()` to get back word-tokenised reviews.  The argument to `.words()` is the file id of an individual review."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KMvFYBPyqe5M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45c262bc-5d0f-4a36-ebcf-c23b3ee4ebd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['films', 'adapted', 'from', 'comic', 'books', 'have', ...]\n"
          ]
        }
      ],
      "source": [
        "print(movie_reviews.words(pos_review_ids[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "68LWdfszqe5M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "outputId": "0c85821f-2d06-4cd2-d4a8-1bab6e544a99"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nltk.corpus.reader.util.StreamBackedCorpusView"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>nltk.corpus.reader.util.StreamBackedCorpusView</b><br/>def __init__(fileid, block_reader=None, startpos=0, encoding=&#x27;utf8&#x27;)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/nltk/corpus/reader/util.py</a>A &#x27;view&#x27; of a corpus file, which acts like a sequence of tokens:\n",
              "it can be accessed by index, iterated over, etc.  However, the\n",
              "tokens are only constructed as-needed -- the entire corpus is\n",
              "never stored in memory at once.\n",
              "\n",
              "The constructor to ``StreamBackedCorpusView`` takes two arguments:\n",
              "a corpus fileid (specified as a string or as a ``PathPointer``);\n",
              "and a block reader.  A &quot;block reader&quot; is a function that reads\n",
              "zero or more tokens from a stream, and returns them as a list.  A\n",
              "very simple example of a block reader is:\n",
              "\n",
              "    &gt;&gt;&gt; def simple_block_reader(stream):\n",
              "    ...     return stream.readline().split()\n",
              "\n",
              "This simple block reader reads a single line at a time, and\n",
              "returns a single token (consisting of a string) for each\n",
              "whitespace-separated substring on the line.\n",
              "\n",
              "When deciding how to define the block reader for a given\n",
              "corpus, careful consideration should be given to the size of\n",
              "blocks handled by the block reader.  Smaller block sizes will\n",
              "increase the memory requirements of the corpus view&#x27;s internal\n",
              "data structures (by 2 integers per block).  On the other hand,\n",
              "larger block sizes may decrease performance for random access to\n",
              "the corpus.  (But note that larger block sizes will *not*\n",
              "decrease performance for iteration.)\n",
              "\n",
              "Internally, ``CorpusView`` maintains a partial mapping from token\n",
              "index to file position, with one entry per block.  When a token\n",
              "with a given index *i* is requested, the ``CorpusView`` constructs\n",
              "it as follows:\n",
              "\n",
              "  1. First, it searches the toknum/filepos mapping for the token\n",
              "     index closest to (but less than or equal to) *i*.\n",
              "\n",
              "  2. Then, starting at the file position corresponding to that\n",
              "     index, it reads one block at a time using the block reader\n",
              "     until it reaches the requested token.\n",
              "\n",
              "The toknum/filepos mapping is created lazily: it is initially\n",
              "empty, but every time a new block is read, the block&#x27;s\n",
              "initial token is added to the mapping.  (Thus, the toknum/filepos\n",
              "map has one entry per block.)\n",
              "\n",
              "In order to increase efficiency for random access patterns that\n",
              "have high degrees of locality, the corpus view may cache one or\n",
              "more blocks.\n",
              "\n",
              ":note: Each ``CorpusView`` object internally maintains an open file\n",
              "    object for its underlying corpus file.  This file should be\n",
              "    automatically closed when the ``CorpusView`` is garbage collected,\n",
              "    but if you wish to close it manually, use the ``close()``\n",
              "    method.  If you access a ``CorpusView``&#x27;s items after it has been\n",
              "    closed, the file object will be automatically re-opened.\n",
              "\n",
              ":warning: If the contents of the file are modified during the\n",
              "    lifetime of the ``CorpusView``, then the ``CorpusView``&#x27;s behavior\n",
              "    is undefined.\n",
              "\n",
              ":warning: If a unicode encoding is specified when constructing a\n",
              "    ``CorpusView``, then the block reader may only call\n",
              "    ``stream.seek()`` with offsets that have been returned by\n",
              "    ``stream.tell()``; in particular, calling ``stream.seek()`` with\n",
              "    relative offsets, or with offsets based on string lengths, may\n",
              "    lead to incorrect behavior.\n",
              "\n",
              ":ivar _block_reader: The function used to read\n",
              "    a single block from the underlying file stream.\n",
              ":ivar _toknum: A list containing the token index of each block\n",
              "    that has been processed.  In particular, ``_toknum[i]`` is the\n",
              "    token index of the first token in block ``i``.  Together\n",
              "    with ``_filepos``, this forms a partial mapping between token\n",
              "    indices and file positions.\n",
              ":ivar _filepos: A list containing the file position of each block\n",
              "    that has been processed.  In particular, ``_toknum[i]`` is the\n",
              "    file position of the first character in block ``i``.  Together\n",
              "    with ``_toknum``, this forms a partial mapping between token\n",
              "    indices and file positions.\n",
              ":ivar _stream: The stream used to access the underlying corpus file.\n",
              ":ivar _len: The total number of tokens in the corpus, if known;\n",
              "    or None, if the number of tokens is not yet known.\n",
              ":ivar _eofpos: The character position of the last character in the\n",
              "    file.  This is calculated when the corpus view is initialized,\n",
              "    and is used to decide when the end of file has been reached.\n",
              ":ivar _cache: A cache of the most recently read block.  It\n",
              "   is encoded as a tuple (start_toknum, end_toknum, tokens), where\n",
              "   start_toknum is the token index of the first token in the block;\n",
              "   end_toknum is the token index of the first token not in the\n",
              "   block; and tokens is a list of the tokens in the block.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 32);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "type(movie_reviews.words(pos_review_ids[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmkD_UEKqe5N"
      },
      "source": [
        "Note, the object returned by `movie_reviews.words()` looks a lot like a list (and behaves a lot like a list) - but it is actually a `StreamBackedCorpusView`.  This essentially means it is not necessarily all in memory  - it is retrieved from disk as needed.  If you want to see all of the words at once then you can convert it to a list using the `list()` constructor.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "XwmV4eh9qe5O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b40566b7-5498-4806-ae96-5f98d8ebb828"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['films', 'adapted', 'from', 'comic', 'books', 'have', 'had', 'plenty', 'of', 'success', ',', 'whether', 'they', \"'\", 're', 'about', 'superheroes', '(', 'batman', ',', 'superman', ',', 'spawn', ')', ',', 'or', 'geared', 'toward', 'kids', '(', 'casper', ')', 'or', 'the', 'arthouse', 'crowd', '(', 'ghost', 'world', ')', ',', 'but', 'there', \"'\", 's', 'never', 'really', 'been', 'a', 'comic', 'book', 'like', 'from', 'hell', 'before', '.', 'for', 'starters', ',', 'it', 'was', 'created', 'by', 'alan', 'moore', '(', 'and', 'eddie', 'campbell', ')', ',', 'who', 'brought', 'the', 'medium', 'to', 'a', 'whole', 'new', 'level', 'in', 'the', 'mid', \"'\", '80s', 'with', 'a', '12', '-', 'part', 'series', 'called', 'the', 'watchmen', '.', 'to', 'say', 'moore', 'and', 'campbell', 'thoroughly', 'researched', 'the', 'subject', 'of', 'jack', 'the', 'ripper', 'would', 'be', 'like', 'saying', 'michael', 'jackson', 'is', 'starting', 'to', 'look', 'a', 'little', 'odd', '.', 'the', 'book', '(', 'or', '\"', 'graphic', 'novel', ',', '\"', 'if', 'you', 'will', ')', 'is', 'over', '500', 'pages', 'long', 'and', 'includes', 'nearly', '30', 'more', 'that', 'consist', 'of', 'nothing', 'but', 'footnotes', '.', 'in', 'other', 'words', ',', 'don', \"'\", 't', 'dismiss', 'this', 'film', 'because', 'of', 'its', 'source', '.', 'if', 'you', 'can', 'get', 'past', 'the', 'whole', 'comic', 'book', 'thing', ',', 'you', 'might', 'find', 'another', 'stumbling', 'block', 'in', 'from', 'hell', \"'\", 's', 'directors', ',', 'albert', 'and', 'allen', 'hughes', '.', 'getting', 'the', 'hughes', 'brothers', 'to', 'direct', 'this', 'seems', 'almost', 'as', 'ludicrous', 'as', 'casting', 'carrot', 'top', 'in', ',', 'well', ',', 'anything', ',', 'but', 'riddle', 'me', 'this', ':', 'who', 'better', 'to', 'direct', 'a', 'film', 'that', \"'\", 's', 'set', 'in', 'the', 'ghetto', 'and', 'features', 'really', 'violent', 'street', 'crime', 'than', 'the', 'mad', 'geniuses', 'behind', 'menace', 'ii', 'society', '?', 'the', 'ghetto', 'in', 'question', 'is', ',', 'of', 'course', ',', 'whitechapel', 'in', '1888', 'london', \"'\", 's', 'east', 'end', '.', 'it', \"'\", 's', 'a', 'filthy', ',', 'sooty', 'place', 'where', 'the', 'whores', '(', 'called', '\"', 'unfortunates', '\"', ')', 'are', 'starting', 'to', 'get', 'a', 'little', 'nervous', 'about', 'this', 'mysterious', 'psychopath', 'who', 'has', 'been', 'carving', 'through', 'their', 'profession', 'with', 'surgical', 'precision', '.', 'when', 'the', 'first', 'stiff', 'turns', 'up', ',', 'copper', 'peter', 'godley', '(', 'robbie', 'coltrane', ',', 'the', 'world', 'is', 'not', 'enough', ')', 'calls', 'in', 'inspector', 'frederick', 'abberline', '(', 'johnny', 'depp', ',', 'blow', ')', 'to', 'crack', 'the', 'case', '.', 'abberline', ',', 'a', 'widower', ',', 'has', 'prophetic', 'dreams', 'he', 'unsuccessfully', 'tries', 'to', 'quell', 'with', 'copious', 'amounts', 'of', 'absinthe', 'and', 'opium', '.', 'upon', 'arriving', 'in', 'whitechapel', ',', 'he', 'befriends', 'an', 'unfortunate', 'named', 'mary', 'kelly', '(', 'heather', 'graham', ',', 'say', 'it', 'isn', \"'\", 't', 'so', ')', 'and', 'proceeds', 'to', 'investigate', 'the', 'horribly', 'gruesome', 'crimes', 'that', 'even', 'the', 'police', 'surgeon', 'can', \"'\", 't', 'stomach', '.', 'i', 'don', \"'\", 't', 'think', 'anyone', 'needs', 'to', 'be', 'briefed', 'on', 'jack', 'the', 'ripper', ',', 'so', 'i', 'won', \"'\", 't', 'go', 'into', 'the', 'particulars', 'here', ',', 'other', 'than', 'to', 'say', 'moore', 'and', 'campbell', 'have', 'a', 'unique', 'and', 'interesting', 'theory', 'about', 'both', 'the', 'identity', 'of', 'the', 'killer', 'and', 'the', 'reasons', 'he', 'chooses', 'to', 'slay', '.', 'in', 'the', 'comic', ',', 'they', 'don', \"'\", 't', 'bother', 'cloaking', 'the', 'identity', 'of', 'the', 'ripper', ',', 'but', 'screenwriters', 'terry', 'hayes', '(', 'vertical', 'limit', ')', 'and', 'rafael', 'yglesias', '(', 'les', 'mis', '?', 'rables', ')', 'do', 'a', 'good', 'job', 'of', 'keeping', 'him', 'hidden', 'from', 'viewers', 'until', 'the', 'very', 'end', '.', 'it', \"'\", 's', 'funny', 'to', 'watch', 'the', 'locals', 'blindly', 'point', 'the', 'finger', 'of', 'blame', 'at', 'jews', 'and', 'indians', 'because', ',', 'after', 'all', ',', 'an', 'englishman', 'could', 'never', 'be', 'capable', 'of', 'committing', 'such', 'ghastly', 'acts', '.', 'and', 'from', 'hell', \"'\", 's', 'ending', 'had', 'me', 'whistling', 'the', 'stonecutters', 'song', 'from', 'the', 'simpsons', 'for', 'days', '(', '\"', 'who', 'holds', 'back', 'the', 'electric', 'car', '/', 'who', 'made', 'steve', 'guttenberg', 'a', 'star', '?', '\"', ')', '.', 'don', \"'\", 't', 'worry', '-', 'it', \"'\", 'll', 'all', 'make', 'sense', 'when', 'you', 'see', 'it', '.', 'now', 'onto', 'from', 'hell', \"'\", 's', 'appearance', ':', 'it', \"'\", 's', 'certainly', 'dark', 'and', 'bleak', 'enough', ',', 'and', 'it', \"'\", 's', 'surprising', 'to', 'see', 'how', 'much', 'more', 'it', 'looks', 'like', 'a', 'tim', 'burton', 'film', 'than', 'planet', 'of', 'the', 'apes', 'did', '(', 'at', 'times', ',', 'it', 'seems', 'like', 'sleepy', 'hollow', '2', ')', '.', 'the', 'print', 'i', 'saw', 'wasn', \"'\", 't', 'completely', 'finished', '(', 'both', 'color', 'and', 'music', 'had', 'not', 'been', 'finalized', ',', 'so', 'no', 'comments', 'about', 'marilyn', 'manson', ')', ',', 'but', 'cinematographer', 'peter', 'deming', '(', 'don', \"'\", 't', 'say', 'a', 'word', ')', 'ably', 'captures', 'the', 'dreariness', 'of', 'victorian', '-', 'era', 'london', 'and', 'helped', 'make', 'the', 'flashy', 'killing', 'scenes', 'remind', 'me', 'of', 'the', 'crazy', 'flashbacks', 'in', 'twin', 'peaks', ',', 'even', 'though', 'the', 'violence', 'in', 'the', 'film', 'pales', 'in', 'comparison', 'to', 'that', 'in', 'the', 'black', '-', 'and', '-', 'white', 'comic', '.', 'oscar', 'winner', 'martin', 'childs', \"'\", '(', 'shakespeare', 'in', 'love', ')', 'production', 'design', 'turns', 'the', 'original', 'prague', 'surroundings', 'into', 'one', 'creepy', 'place', '.', 'even', 'the', 'acting', 'in', 'from', 'hell', 'is', 'solid', ',', 'with', 'the', 'dreamy', 'depp', 'turning', 'in', 'a', 'typically', 'strong', 'performance', 'and', 'deftly', 'handling', 'a', 'british', 'accent', '.', 'ians', 'holm', '(', 'joe', 'gould', \"'\", 's', 'secret', ')', 'and', 'richardson', '(', '102', 'dalmatians', ')', 'log', 'in', 'great', 'supporting', 'roles', ',', 'but', 'the', 'big', 'surprise', 'here', 'is', 'graham', '.', 'i', 'cringed', 'the', 'first', 'time', 'she', 'opened', 'her', 'mouth', ',', 'imagining', 'her', 'attempt', 'at', 'an', 'irish', 'accent', ',', 'but', 'it', 'actually', 'wasn', \"'\", 't', 'half', 'bad', '.', 'the', 'film', ',', 'however', ',', 'is', 'all', 'good', '.', '2', ':', '00', '-', 'r', 'for', 'strong', 'violence', '/', 'gore', ',', 'sexuality', ',', 'language', 'and', 'drug', 'content']\n"
          ]
        }
      ],
      "source": [
        "print(list(movie_reviews.words(pos_review_ids[0])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXWztGUZqe5P"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gUYw61N7iQo"
      },
      "source": [
        "## Creating training and testing sets\n",
        "You will be training and testing various document classifiers. It is essential that the data used in the testing phase is not used during the training phase, since this can lead to overestimating performance.\n",
        "\n",
        "We now introduce the `split_data` function (defined in the cell below) which can be used to get separate **training** and **testing** sets.\n",
        "\n",
        "> Look through the code in the following cell, reading the comments and making sure that you understand each line."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "HsMcMo5e7iQp"
      },
      "outputs": [],
      "source": [
        "import random # have a look at the documentation at https://docs.python.org/3/library/random.html\n",
        "\n",
        "\n",
        "def split_data(data, ratio=0.7): # when the second argument is not given, it defaults to 0.7\n",
        "    \"\"\"\n",
        "    Given collection of items and ratio:\n",
        "     - partitions the collection into training and testing, where the proportion in training is ratio,\n",
        "\n",
        "    :param data: A list (or generator) of documents or doc ids\n",
        "    :param ratio: The proportion of training documents (default 0.7)\n",
        "    :return: a pair (tuple) of lists where the first element of the\n",
        "            pair is a list of the training data and the second is a list of the test data.\n",
        "    \"\"\"\n",
        "\n",
        "    n = len(data)  #Found out number of samples present.  data could be a list or a generator\n",
        "    train_indices = random.sample(range(n), int(n * ratio))          #Randomly select training indices\n",
        "    test_indices = list(set(range(n)) - set(train_indices))   #Other items are testing indices\n",
        "\n",
        "    train = [data[i] for i in train_indices]           #Use training indices to select data\n",
        "    test = [data[i] for i in test_indices]             #Use testing indices to select data\n",
        "\n",
        "    return (train, test)                       #Return split data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iu1pTJhr7iQu"
      },
      "source": [
        "Now we can use this function to create training and testing data.  First, we need to create 4 lists:\n",
        "    * file ids  of positive docs to go in the training data\n",
        "    * file ids of positive docs to go in the testing data\n",
        "    * file ids of negative docs to go in the training data\n",
        "    * file ids of negative docs to go in the testing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QUVZGOpJ7iQv"
      },
      "outputs": [],
      "source": [
        "random.seed(41)  #set the random seeds so these random splits are always the same\n",
        "pos_train_ids, pos_test_ids = split_data(pos_review_ids)\n",
        "neg_train_ids, neg_test_ids = split_data(neg_review_ids)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQjhg51zqe5R"
      },
      "source": [
        "Now, we want to create our labelled data sets.   We need to associate each review with its label so that later we can shuffle up all of the training data (and the testing data)\n",
        "\n",
        "### Exercise 1\n",
        "Write some python code which will construct a training set (`training`) and a test set (`testing`) from the data.  Each set should be a list of pairs where each pair is a list of words and a label, as below:\n",
        "\n",
        "<code>[([list,of,words],'label'),([list,of,words],'label'),...]</code>\n",
        "\n",
        "Hint:  You can do this with 4 list comprehensions and list concatenation.\n",
        "\n",
        "Check the size of `training` and `testing`.  Using a 70\\% split, how many should be in each?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "yP5wctINNDUS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "d6de5a0b-5d63-4752-837d-ce2da0763623"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(['melvin', 'udall', 'is', 'a', 'heartless', 'man', '.', ...], 'pos_train'),\n",
              " (['why', 'do', 'people', 'hate', 'the', 'spice', ...], 'pos_train'),\n",
              " (['jerry', 'springer', 'has', 'got', 'nothing', 'on', ...], 'pos_train'),\n",
              " (['i', 'don', \"'\", 't', 'know', 'what', 'movie', 'the', ...], 'pos_train'),\n",
              " (['ingredients', ':', 'down', '-', 'on', '-', 'his', ...], 'pos_train'),\n",
              " (['when', 'i', 'initially', 'set', 'out', 'to', ...], 'pos_train'),\n",
              " (['defending', 'your', 'life', 'is', 'an', ...], 'pos_train'),\n",
              " (['for', 'this', 'review', 'and', 'more', ',', 'visit', ...], 'pos_train'),\n",
              " (['plot', ':', 'a', 'dude', 'and', 'his', 'brother', ...], 'pos_train'),\n",
              " (['touchstone', 'pictures', 'and', 'spyglass', ...], 'pos_train'),\n",
              " (['slavery', 'is', 'bad', '.', 'after', 'hundreds', ...], 'pos_train'),\n",
              " (['note', ':', 'some', 'may', 'consider', 'portions', ...], 'pos_train'),\n",
              " (['trailing', 'the', 'success', 'of', 'brit', 'humour', ...], 'pos_train'),\n",
              " (['the', 'first', 'thing', 'you', 'notice', 'about', ...], 'pos_train'),\n",
              " (['robert', 'redford', 'is', 'very', 'good', 'at', ...], 'pos_train'),\n",
              " (['go', \"'\", 's', 'is', 'a', 'gloriously', 'slick', ...], 'pos_train'),\n",
              " (['robocop', 'is', 'an', 'intelligent', 'science', ...], 'pos_train'),\n",
              " (['\"', 'remember', 'what', 'the', 'mpaa', 'says', ':', ...], 'pos_train'),\n",
              " (['the', 'american', 'action', 'film', 'has', 'been', ...], 'pos_train'),\n",
              " (['veteran', 'actor', 'clint', 'eastwood', 'has', ...], 'pos_train'),\n",
              " (['it', 'is', 'often', 'said', 'by', 'his', 'fans', ...], 'pos_train'),\n",
              " ([\"'\", 'pleasantville', \"'\", '(', '1998', ')', 'taps', ...], 'pos_train'),\n",
              " (['it', 'is', 'with', 'hesitance', 'that', 'i', 'call', ...], 'pos_train'),\n",
              " (['having', 'not', 'seen', ',', '\"', 'who', 'framed', ...], 'pos_train'),\n",
              " (['this', 'is', 'a', 'good', 'year', 'if', 'you', ...], 'pos_train'),\n",
              " (['at', 'one', 'point', 'during', 'brian', 'de', ...], 'pos_train'),\n",
              " (['with', 'more', 'and', 'more', 'television', 'shows', ...], 'pos_train'),\n",
              " (['jack', 'nicholson', 'has', 'a', 'funny', 'way', 'of', ...], 'pos_train'),\n",
              " (['a', 'couple', 'of', 'months', 'ago', ',', 'when', ...], 'pos_train'),\n",
              " (['most', 'movies', 'seem', 'to', 'release', 'a', ...], 'pos_train'),\n",
              " (['it', 'was', 'with', 'great', 'trepidation', 'that', ...], 'pos_train'),\n",
              " (['american', 'pie', 'acknowledges', 'a', 'cold', ',', ...], 'pos_train'),\n",
              " (['whenever', 'studio', 'executives', 'try', 'to', ...], 'pos_train'),\n",
              " (['the', 'reunion', 'film', 'is', 'not', 'an', ...], 'pos_train'),\n",
              " (['in', 'one', 'scene', 'from', '\"', 'the', 'people', ...], 'pos_train'),\n",
              " (['\"', 'say', ',', 'any', 'of', 'you', 'know', 'how', ...], 'pos_train'),\n",
              " (['after', 'watching', 'the', 'first', 'ten', 'minutes', ...], 'pos_train'),\n",
              " (['warning', ':', 'this', 'review', 'contains', 'some', ...], 'pos_train'),\n",
              " (['contact', '(', 'pg', ')', 'there', \"'\", 's', 'a', ...], 'pos_train'),\n",
              " (['i', 'rented', '\"', 'brokedown', 'palace', '\"', ...], 'pos_train'),\n",
              " (['in', 'wonder', 'boys', 'michael', 'douglas', 'plays', ...], 'pos_train'),\n",
              " (['seen', 'august', '8', ',', '1998', 'at', '6', 'p', ...], 'pos_train'),\n",
              " (['the', 'laserman', ':', 'somehow', 'the', 'title', ...], 'pos_train'),\n",
              " (['notting', 'hill', \"'\", 's', 'trailer', 'is', 'awful', ...], 'pos_train'),\n",
              " (['an', 'indian', 'runner', 'was', 'more', 'than', 'a', ...], 'pos_train'),\n",
              " (['you', \"'\", 've', 'probably', 'heard', 'the', 'one', ...], 'pos_train'),\n",
              " (['expand', 'the', 'final', 'fifteen', 'minutes', 'of', ...], 'pos_train'),\n",
              " (['mpaa', ':', 'not', 'rated', '(', 'though', 'i', ...], 'pos_train'),\n",
              " (['once', 'again', ',', 'the', 'battle', 'is', ...], 'pos_train'),\n",
              " (['titanic', 'is', ',', 'without', 'a', 'doubt', ',', ...], 'pos_train'),\n",
              " (['now', 'that', '\"', 'boogie', 'nights', '\"', 'has', ...], 'pos_train'),\n",
              " (['every', 'once', 'in', 'a', 'while', 'a', 'movie', ...], 'pos_train'),\n",
              " (['capsule', ':', 'the', 'verma', 'family', 'is', ...], 'pos_train'),\n",
              " (['eric', 'rohmer', \"'\", 's', '\"', 'pauline', 'at', ...], 'pos_train'),\n",
              " (['\"', 'the', 'fighting', 'sullivans', '\"', 'contains', ...], 'pos_train'),\n",
              " (['robert', 'redford', \"'\", 's', 'a', 'river', 'runs', ...], 'pos_train'),\n",
              " (['i', 'have', 'to', 'say', 'it', '.', 'tim', 'burton', ...], 'pos_train'),\n",
              " (['after', 'a', 'stylistic', 'detour', 'with', 'mrs', ...], 'pos_train'),\n",
              " (['a', 'thriller', 'set', 'in', 'modern', 'day', ...], 'pos_train'),\n",
              " (['the', 'story', 'of', 'us', ',', 'a', 'rob', 'reiner', ...], 'pos_train'),\n",
              " (['mary', 'norton', \"'\", 's', 'children', \"'\", 's', ...], 'pos_train'),\n",
              " (['if', 'there', 'is', 'one', 'thing', 'that', ...], 'pos_train'),\n",
              " (['the', 'saint', 'was', 'actually', 'a', 'little', ...], 'pos_train'),\n",
              " (['up', 'until', 'about', 'a', 'year', 'ago', ',', ...], 'pos_train'),\n",
              " (['in', 'arguably', 'the', 'most', 'anticipated', ...], 'pos_train'),\n",
              " (['i', 'remember', 'hearing', 'about', 'this', 'film', ...], 'pos_train'),\n",
              " (['well', ',', 'i', \"'\", 'll', 'admit', 'when', 'i', ...], 'pos_train'),\n",
              " (['if', 'you', 'had', 'a', 'chance', 'to', 'create', ...], 'pos_train'),\n",
              " (['for', 'those', 'of', 'us', 'who', 'weren', \"'\", 't', ...], 'pos_train'),\n",
              " (['did', 'you', 'ever', 'wonder', 'if', 'dennis', ...], 'pos_train'),\n",
              " (['here', 'is', 'a', 'film', 'that', 'is', 'so', ...], 'pos_train'),\n",
              " (['i', \"'\", 've', 'never', 'been', 'a', 'member', 'of', ...], 'pos_train'),\n",
              " (['what', 'if', 'one', 'of', 'our', 'cities', 'became', ...], 'pos_train'),\n",
              " (['gere', ',', 'willis', ',', 'poitier', 'chase', ...], 'pos_train'),\n",
              " (['you', \"'\", 'd', 'think', 'it', 'would', 'be', 'easy', ...], 'pos_train'),\n",
              " (['\"', 'through', 'a', 'spyglass', ',', 'i', 'could', ...], 'pos_train'),\n",
              " (['disney', \"'\", 's', '35th', 'animated', 'feature', ...], 'pos_train'),\n",
              " (['the', 'dream', 'team', 'is', 'a', 'thoroughly', ...], 'pos_train'),\n",
              " (['the', 'uncompromising', 'nudity', 'bared', ...], 'pos_train'),\n",
              " (['the', 'long', 'and', 'illustrious', 'career', 'of', ...], 'pos_train'),\n",
              " (['not', 'since', 'oliver', 'stone', \"'\", 's', ...], 'pos_train'),\n",
              " (['melvin', 'van', 'peebles', \"'\", '\"', 'sweet', ...], 'pos_train'),\n",
              " (['\"', 'crazy', '/', 'beautiful', '\"', 'suffers', ...], 'pos_train'),\n",
              " (['ingredients', ':', 'little', 'orphan', 'boy', ',', ...], 'pos_train'),\n",
              " (['a', 'fully', 'loaded', 'entertainment', 'review', ...], 'pos_train'),\n",
              " (['plot', ':', 'a', 'big', '-', 'time', 'momma', \"'\", ...], 'pos_train'),\n",
              " (['renown', 'surrealist', 'director', ',', 'the', '77', ...], 'pos_train'),\n",
              " (['some', 'critics', ',', 'including', 'siskel', '&', ...], 'pos_train'),\n",
              " (['for', 'those', 'who', 'associate', 'italian', ...], 'pos_train'),\n",
              " (['in', ',', '\"', 'the', 'muse', '\"', 'albert', ...], 'pos_train'),\n",
              " (['near', 'the', 'end', 'of', 'frank', 'capra', \"'\", ...], 'pos_train'),\n",
              " (['what', 'do', 'you', 'get', 'when', 'you', 'combine', ...], 'pos_train'),\n",
              " (['many', 'people', 'dislike', 'french', 'films', 'for', ...], 'pos_train'),\n",
              " (['the', 'second', 'jackal', '-', 'based', 'film', 'to', ...], 'pos_train'),\n",
              " (['no', 'film', 'in', 'recent', 'has', 'left', 'me', ...], 'pos_train'),\n",
              " (['\"', '.', '.', 'it', \"'\", 's', 'certainly', 'more', ...], 'pos_train'),\n",
              " (['in', 'a', 'flashback', ',', 'the', 'teenage', 'girl', ...], 'pos_train'),\n",
              " (['countries', 'and', 'legal', 'systems', 'that', ...], 'pos_train'),\n",
              " (['there', 'are', 'times', 'when', 'the', 'success', ...], 'pos_train'),\n",
              " (['\"', 'dangerous', 'beauty', '\"', 'is', 'a', 'really', ...], 'pos_train'),\n",
              " (['what', 'is', 'freedom', '?', 'how', 'does', 'one', ...], 'pos_train'),\n",
              " (['according', 'to', 'hollywood', 'movies', 'made', ...], 'pos_train'),\n",
              " (['note', ':', 'some', 'may', 'consider', 'portions', ...], 'pos_train'),\n",
              " (['\"', 'the', 'blair', 'witch', 'project', '\"', 'was', ...], 'pos_train'),\n",
              " (['the', 'police', 'negotiator', 'is', 'the', 'person', ...], 'pos_train'),\n",
              " (['is', 'it', 'just', 'me', ',', 'or', 'have', 'disney', ...], 'pos_train'),\n",
              " (['let', \"'\", 's', 'face', 'it', ':', 'the', '$', '100', ...], 'pos_train'),\n",
              " (['synopsis', ':', 'retiring', 'detective', 'jerry', ...], 'pos_train'),\n",
              " (['i', 'know', 'what', 'i', 'would', 'do', 'with', '$', ...], 'pos_train'),\n",
              " (['it', 'is', 'hard', 'to', 'imagine', 'that', 'a', ...], 'pos_train'),\n",
              " (['there', \"'\", 's', 'a', 'thin', 'line', 'between', ...], 'pos_train'),\n",
              " (['you', \"'\", 've', 'seen', 'this', 'moment', 'before', ...], 'pos_train'),\n",
              " (['i', 'was', 'born', 'in', '1970', ',', 'which', ...], 'pos_train'),\n",
              " (['\"', 'he', \"'\", 's', 'back', ',', 'and', 'it', \"'\", ...], 'pos_train'),\n",
              " (['it', 'is', 'easy', 'to', 'see', 'why', 'the', 'late', ...], 'pos_train'),\n",
              " (['this', 'is', 'the', 'movie', 'not', 'the', 'perfume', ...], 'pos_train'),\n",
              " (['a', 'frequent', 'error', 'is', 'the', ...], 'pos_train'),\n",
              " (['this', 'has', 'been', 'an', 'extraordinary', 'year', ...], 'pos_train'),\n",
              " (['men', 'in', 'black', 'is', 'an', 'explosive', 'mix', ...], 'pos_train'),\n",
              " (['mike', 'myers', ',', 'you', 'certainly', 'did', ...], 'pos_train'),\n",
              " (['>', 'from', 'the', 'commercials', ',', 'this', ...], 'pos_train'),\n",
              " (['in', 'my', 'reviews', 'i', 'try', 'to', 'make', ...], 'pos_train'),\n",
              " (['\"', 'a', 'private', 'matter', '\"', 'is', 'based', ...], 'pos_train'),\n",
              " (['while', 'watching', 'wes', 'anderson', \"'\", 's', ...], 'pos_train'),\n",
              " (['seen', 'at', 'the', '21st', 'portland', ...], 'pos_train'),\n",
              " (['along', 'his', 'carreer', ',', 'mel', 'gibson', ...], 'pos_train'),\n",
              " (['copyright', '1996', 'graeme', 'huggan', 'carry', ...], 'pos_train'),\n",
              " (['is', 'jimmy', 'stewart', 'the', 'greatest', 'actor', ...], 'pos_train'),\n",
              " (['notice', ':', 'this', 'is', 'a', 'review', 'and', ...], 'pos_train'),\n",
              " (['i', 'feel', 'no', 'hesitation', 'in', 'saying', ...], 'pos_train'),\n",
              " (['capsule', ':', 'this', 'is', 'a', '1950s', 'or', ...], 'pos_train'),\n",
              " (['on', 'april', '12th', ',', '1912', ',', 'the', ...], 'pos_train'),\n",
              " (['a', 'miracle', 'of', 'filmmaking', ',', '\"', 'some', ...], 'pos_train'),\n",
              " (['it', 'is', 'always', 'refreshing', 'to', 'see', 'a', ...], 'pos_train'),\n",
              " (['perhaps', 'it', \"'\", 's', 'time', 'for', 'me', 'to', ...], 'pos_train'),\n",
              " (['if', 'you', 'want', 'some', 'hearty', 'laughs', ',', ...], 'pos_train'),\n",
              " (['what', 'is', 'a', 'scary', 'movie', 'anyhow', '?', ...], 'pos_train'),\n",
              " (['118', 'minutes', ';', 'not', 'rated', '(', 'though', ...], 'pos_train'),\n",
              " (['life', 'is', 'beautiful', 'is', 'a', 'rare', 'treat', ...], 'pos_train'),\n",
              " (['\"', 'love', 'is', 'the', 'devil', '\"', 'is', 'a', ...], 'pos_train'),\n",
              " (['capsule', ':', 'this', 'is', 'a', 'harrowing', ...], 'pos_train'),\n",
              " (['you', 'know', 'you', \"'\", 're', 'in', 'for', 'a', ...], 'pos_train'),\n",
              " (['with', 'a', 'team', 'of', '200', 'graphic', ...], 'pos_train'),\n",
              " (['there', 'must', 'be', 'some', 'unwritten', 'rule', ...], 'pos_train'),\n",
              " (['deep', 'rising', 'is', 'one', 'of', '\"', 'those', ...], 'pos_train'),\n",
              " (['wild', 'things', 'is', 'a', 'suspenseful', ...], 'pos_train'),\n",
              " (['there', 'seem', 'to', 'be', 'two', 'reactions', 'to', ...], 'pos_train'),\n",
              " (['ok', ',', 'let', \"'\", 's', 'get', 'one', 'thing', ...], 'pos_train'),\n",
              " (['harmless', ',', 'silly', 'and', 'fun', 'comedy', ...], 'pos_train'),\n",
              " (['bruce', 'barth', \"'\", 's', 'mellow', 'piano', ...], 'pos_train'),\n",
              " (['the', 'characters', 'in', '\"', 'palmetto', '\"', ...], 'pos_train'),\n",
              " (['curdled', 'is', 'a', 'deliciously', 'dark', 'and', ...], 'pos_train'),\n",
              " (['trees', 'lounge', 'is', 'the', 'directoral', 'debut', ...], 'pos_train'),\n",
              " (['\"', 'gattaca', '\"', 'represents', 'a', 'solid', ...], 'pos_train'),\n",
              " (['it', \"'\", 's', 'not', 'often', 'that', 'i', 'laugh', ...], 'pos_train'),\n",
              " (['in', 'the', 'company', 'of', 'men', 'made', 'a', ...], 'pos_train'),\n",
              " (['it', 'was', 'only', 'a', 'matter', 'of', 'time', ...], 'pos_train'),\n",
              " (['director', ':', 'penelope', 'spheeris', '(', ...], 'pos_train'),\n",
              " (['available', 'in', 'an', 'all', 'new', 'video', ...], 'pos_train'),\n",
              " (['bruce', 'willis', 'is', 'a', 'type', '-', 'casted', ...], 'pos_train'),\n",
              " (['the', 'jekyll', 'and', 'hyde', 'story', 'told', ...], 'pos_train'),\n",
              " (['the', 'word', \"'\", 'rest', \"'\", 'in', 'the', 'title', ...], 'pos_train'),\n",
              " (['trekkies', ',', 'roger', 'nygard', \"'\", 's', ...], 'pos_train'),\n",
              " (['steve', 'martin', 'took', 'an', 'extended', ...], 'pos_train'),\n",
              " (['a', 'big', 'surprise', 'to', 'me', '.', 'the', ...], 'pos_train'),\n",
              " (['it', 'must', 'be', 'tough', 'to', 'be', 'a', 'mob', ...], 'pos_train'),\n",
              " (['susan', 'granger', \"'\", 's', 'review', 'of', '\"', ...], 'pos_train'),\n",
              " (['larry', 'flynt', 'is', 'a', 'self', 'proclaimed', ...], 'pos_train'),\n",
              " (['when', 'you', 'go', 'to', 'the', 'movies', 'as', ...], 'pos_train'),\n",
              " (['you', \"'\", 've', 'heard', 'all', 'the', 'hype', '.', ...], 'pos_train'),\n",
              " (['this', 'is', 'one', 'of', 'the', 'most', 'funny', ...], 'pos_train'),\n",
              " (['i', 'tried', 'hard', 'not', 'like', 'this', 'movie', ...], 'pos_train'),\n",
              " (['the', 'trailers', 'and', 'the', 'beginning', 'of', ...], 'pos_train'),\n",
              " (['you', 'don', \"'\", 't', 'have', 'to', 'know', 'poker', ...], 'pos_train'),\n",
              " (['\"', 'the', 'tailor', 'of', 'panama', '\"', 'is', 'a', ...], 'pos_train'),\n",
              " (['what', 'a', 'great', 'film', '.', 'what', 'a', ...], 'pos_train'),\n",
              " (['ingredients', ':', 'pouring', 'rain', ',', 'small', ...], 'pos_train'),\n",
              " (['oh', 'god', 'how', 'many', 'john', 'grisham', ...], 'pos_train'),\n",
              " (['this', 'movie', 'was', 'one', 'of', 'the', 'first', ...], 'pos_train'),\n",
              " (['if', 'beavis', 'and', 'butthead', 'had', 'a', ...], 'pos_train'),\n",
              " (['i', 'like', 'movies', 'with', 'albert', 'brooks', ...], 'pos_train'),\n",
              " (['i', 'guess', 'it', \"'\", 's', 'a', 'credit', 'to', ...], 'pos_train'),\n",
              " (['scream', '2', 'isn', \"'\", 't', 'quite', 'as', ...], 'pos_train'),\n",
              " (['there', \"'\", 's', 'more', 'to', 'a', 'quilt', 'than', ...], 'pos_train'),\n",
              " (['\"', 'a', 'bug', \"'\", 's', 'life', '\"', 'may', 'not', ...], 'pos_train'),\n",
              " (['plot', ':', 'odin', 'is', 'a', 'great', 'high', ...], 'pos_train'),\n",
              " (['making', 'a', 'sequel', 'to', 'a', 'widely', ...], 'pos_train'),\n",
              " (['here', \"'\", 's', 'a', 'word', 'analogy', ':', ...], 'pos_train'),\n",
              " (['i', 'relish', 'those', 'rare', 'opportunities', ...], 'pos_train'),\n",
              " (['warning', ':', 'if', 'you', 'actually', 'wish', 'to', ...], 'pos_train'),\n",
              " (['at', 'first', 'glance', ',', 'three', 'kings', ...], 'pos_train'),\n",
              " (['scream', '2', 'has', 'a', 'titillating', 'little', ...], 'pos_train'),\n",
              " (['the', 'sweet', 'hereafter', 'could', 'serve', 'as', ...], 'pos_train'),\n",
              " (['damn', 'those', 'trailers', '.', 'had', 'it', 'not', ...], 'pos_train'),\n",
              " (['seen', 'february', '15', ',', '1998', 'on', 'home', ...], 'pos_train'),\n",
              " (['john', 'von', 'neumann', ',', 'progenitor', 'of', ...], 'pos_train'),\n",
              " (['as', 'i', 'write', 'the', 'review', 'for', 'the', ...], 'pos_train'),\n",
              " (['in', 'some', 'respects', ',', 'rush', 'hour', 'is', ...], 'pos_train'),\n",
              " (['for', 'example', ',', 'in', 'happy', 'gilmore', ',', ...], 'pos_train'),\n",
              " (['`', 'oh', 'behave', '!', 'felicity', 'shagwell', ...], 'pos_train'),\n",
              " (['elizabeth', 'is', 'a', 'potent', 'historical', ...], 'pos_train'),\n",
              " (['linda', 'fiorentino', 'disappeared', 'off', 'the', ...], 'pos_train'),\n",
              " (['synopsis', ':', 'as', 'a', 'response', 'to', ...], 'pos_train'),\n",
              " (['in', 'october', 'of', '1997', ',', 'audiences', ...], 'pos_train'),\n",
              " (['sam', '(', 'matthew', 'broderick', ')', 'is', 'an', ...], 'pos_train'),\n",
              " (['synopsis', ':', 'committed', 'to', 'an', 'asylum', ...], 'pos_train'),\n",
              " (['\"', 'a', 'man', 'is', 'not', 'a', 'man', 'without', ...], 'pos_train'),\n",
              " (['with', 'storytelling', 'this', 'compelling', ',', ...], 'pos_train'),\n",
              " (['\"', 'take', 'a', 'number', ',', 'fill', 'out', 'a', ...], 'pos_train'),\n",
              " (['james', 'jones', ',', 'one', 'of', 'the', 'major', ...], 'pos_train'),\n",
              " (['capsule', ':', 'the', 'director', 'of', 'cure', ...], 'pos_train'),\n",
              " (['i', 'saw', 'simon', 'birch', 'in', 'a', 'basically', ...], 'pos_train'),\n",
              " (['ladies', 'and', 'gentlemen', ',', '1997', \"'\", 's', ...], 'pos_train'),\n",
              " (['robert', 'altman', \"'\", 's', 'cookie', \"'\", 's', ...], 'pos_train'),\n",
              " (['screen', 'story', 'by', 'kevin', 'yagher', 'and', ...], 'pos_train'),\n",
              " (['will', 'hunting', '(', 'matt', 'damon', ')', 'is', ...], 'pos_train'),\n",
              " (['of', 'circumcision', ',', 'psychic', 'wounds', 'and', ...], 'pos_train'),\n",
              " (['so', 'here', 'is', 'the', 'second', 'of', '1999', ...], 'pos_train'),\n",
              " (['a', 'group', 'of', 'high', 'school', 'kids', 'mix', ...], 'pos_train'),\n",
              " (['`', 'run', 'lola', 'run', \"'\", ',', 'a', 'german', ...], 'pos_train'),\n",
              " (['america', 'has', 'finally', 'gotten', 'what', 'it', ...], 'pos_train'),\n",
              " (['\"', 'sometimes', 'the', \"'\", 'green', 'mile', \"'\", ...], 'pos_train'),\n",
              " (['the', 'farrelly', 'brothers', \"'\", 'third', 'film', ...], 'pos_train'),\n",
              " (['it', 'was', 'a', 'rainy', 'friday', 'afternoon', ...], 'pos_train'),\n",
              " (['confession', 'time', ':', 'i', 'have', 'never', ',', ...], 'pos_train'),\n",
              " (['lisa', 'cholodenko', \"'\", 's', '\"', 'high', 'art', ...], 'pos_train'),\n",
              " (['the', 'deer', 'hunter', ',', 'directed', 'by', ...], 'pos_train'),\n",
              " (['one', 'way', 'of', 'telling', 'if', 'a', 'film', ...], 'pos_train'),\n",
              " (['let', \"'\", 's', 'face', 'it', ':', 'since', ...], 'pos_train'),\n",
              " (['this', 'reviewer', 'is', 'ignorant', 'of', 'what', ...], 'pos_train'),\n",
              " (['glory', '--', 'starring', 'matthew', 'broderick', ...], 'pos_train'),\n",
              " (['mimi', 'leder', 'is', 'probably', 'best', 'known', ...], 'pos_train'),\n",
              " (['director', 'jan', 'de', 'bont', 'certainly', 'knows', ...], 'pos_train'),\n",
              " (['a', 'cinematic', 'version', 'of', 'one', 'of', ...], 'pos_train'),\n",
              " (['we', 'all', 'know', 'the', 'fate', 'of', '\"', ...], 'pos_train'),\n",
              " (['gordon', 'fleming', '(', 'peter', 'mullan', ')', ...], 'pos_train'),\n",
              " (['by', 'now', 'i', 'figured', 'i', \"'\", 'd', 'seen', ...], 'pos_train'),\n",
              " (['i', 'find', 'most', 'of', 'television', 'so', ...], 'pos_train'),\n",
              " (['frequency', 'n', '.', ',', 'the', 'number', 'of', ...], 'pos_train'),\n",
              " (['there', 'are', 'certain', 'people', 'in', 'the', ...], 'pos_train'),\n",
              " (['once', 'upon', 'a', 'time', 'a', 'solitary', 'ogre', ...], 'pos_train'),\n",
              " (['\"', 'being', 'john', 'malkovich', '\"', 'is', 'the', ...], 'pos_train'),\n",
              " (['call', 'it', 'touched', 'by', 'a', 'demon', '.', ...], 'pos_train'),\n",
              " (['it', 'may', 'seem', 'weird', 'to', 'begin', 'a', ...], 'pos_train'),\n",
              " (['apocalypse', 'now', ',', 'based', 'on', 'the', ...], 'pos_train'),\n",
              " (['magnolia', 'left', 'me', 'relling', 'from', 'the', ...], 'pos_train'),\n",
              " (['in', 'chocolat', ',', 'a', 'chocolate', 'shop', ...], 'pos_train'),\n",
              " (['\"', 'six', 'days', ',', 'seven', 'nights', '\"', 'is', ...], 'pos_train'),\n",
              " (['of', 'the', 'major', 'horror', 'sub', '-', 'genres', ...], 'pos_train'),\n",
              " (['i', 'swear', 'i', 'have', 'seen', 'the', 'edge', ...], 'pos_train'),\n",
              " (['just', 'in', 'time', 'for', 'halloween', 'and', ...], 'pos_train'),\n",
              " (['most', 'sequels', 'don', \"'\", 't', 'do', 'what', ...], 'pos_train'),\n",
              " (['when', 'andy', 'leaves', 'for', 'cowboy', 'camp', ...], 'pos_train'),\n",
              " (['no', 'humans', 'were', 'harmed', ',', 'tested', 'or', ...], 'pos_train'),\n",
              " (['capsule', ':', 'side', '-', 'splitting', 'comedy', ...], 'pos_train'),\n",
              " (['sometimes', 'i', 'find', '19th', 'century', ...], 'pos_train'),\n",
              " (['note', ':', 'some', 'may', 'consider', 'portions', ...], 'pos_train'),\n",
              " (['i', 'know', 'it', 'already', 'opened', 'in', ...], 'pos_train'),\n",
              " (['i', 'was', 'fortunate', 'enough', 'to', 'attend', ...], 'pos_train'),\n",
              " (['one', 'of', 'the', 'best', 'movies', 'i', \"'\", 've', ...], 'pos_train'),\n",
              " (['capsule', ':', 'the', 'best', 'place', 'to', 'start', ...], 'pos_train'),\n",
              " (['the', 'central', 'focus', 'of', 'michael', ...], 'pos_train'),\n",
              " (['steve', 'soderbergh', \"'\", 's', '\"', 'sex', ',', ...], 'pos_train'),\n",
              " (['the', 'most', 'common', '(', 'and', 'in', 'many', ...], 'pos_train'),\n",
              " (['some', 'of', 'my', 'friends', 'who', 'went', 'to', ...], 'pos_train'),\n",
              " (['a', 'common', 'complaint', 'amongst', 'film', ...], 'pos_train'),\n",
              " (['billed', 'as', 'a', '\"', 'feminist', 'sex', ...], 'pos_train'),\n",
              " (['are', 'we', 'victims', 'of', 'fate', 'in', 'life', ...], 'pos_train'),\n",
              " (['one', 'never', 'quite', 'knows', 'what', 'one', 'is', ...], 'pos_train'),\n",
              " (['there', \"'\", 's', 'a', 'moment', 'in', 'schindler', ...], 'pos_train'),\n",
              " (['summary', 'five', 'liberal', 'iowa', 'graduate', ...], 'pos_train'),\n",
              " (['a', 'fully', 'loaded', 'entertainment', 'review', ...], 'pos_train'),\n",
              " (['david', 'cronenberg', 'presents', 'us', 'with', ...], 'pos_train'),\n",
              " (['carry', 'on', 'matron', 'is', 'the', 'last', 'great', ...], 'pos_train'),\n",
              " (['the', '\"', 'submarine', '\"', 'genre', 'of', 'movies', ...], 'pos_train'),\n",
              " (['virtual', 'reality', 'is', 'a', 'topic', 'that', ...], 'pos_train'),\n",
              " (['it', 'was', 'a', 'crazy', 'time', 'in', 'france', ...], 'pos_train'),\n",
              " (['ingredients', ':', 'london', 'gal', ',', 'fate', ',', ...], 'pos_train'),\n",
              " (['george', 'little', '(', 'jonathan', 'lipnicki', ')', ...], 'pos_train'),\n",
              " (['capsule', ':', 'a', 'rock', 'and', 'roll', 'fable', ...], 'pos_train'),\n",
              " (['the', 'premise', 'of', 'the', 'new', 'teen', '-', ...], 'pos_train'),\n",
              " (['carla', 'gugino', 'graduates', 'from', 'high', ...], 'pos_train'),\n",
              " (['brian', 'depalma', 'needs', 'a', 'hit', '*', ...], 'pos_train'),\n",
              " (['getting', 'it', 'right', 'is', 'a', 'far', 'far', ...], 'pos_train'),\n",
              " (['the', 'party', 'is', 'one', 'of', 'those', 'classic', ...], 'pos_train'),\n",
              " (['with', 'the', 'opening', 'scene', 'of', 'a', 'young', ...], 'pos_train'),\n",
              " (['the', 'release', 'of', 'dolores', 'claiborne', ...], 'pos_train'),\n",
              " (['those', 'of', 'you', 'who', 'frequently', 'read', ...], 'pos_train'),\n",
              " (['i', 'remember', 'seeing', 'the', 'trailer', 'of', ...], 'pos_train'),\n",
              " (['call', '911', 'for', 'the', 'cliche', 'police', 'if', ...], 'pos_train'),\n",
              " (['plot', ':', 'a', 'group', 'of', 'asbestos', ...], 'pos_train'),\n",
              " (['the', 'heist', 'of', 'a', 'flawless', ',', '84', ...], 'pos_train'),\n",
              " (['(', 'dimension', 'films', ',', '\"', 'scream', '2', ...], 'pos_train'),\n",
              " (['jake', 'kasdan', ',', 'son', 'of', 'one', 'of', ...], 'pos_train'),\n",
              " (['good', 'films', 'are', 'hard', 'to', 'find', 'these', ...], 'pos_train'),\n",
              " (['`', 'we', 'run', 'tings', '.', 'tings', 'don', \"'\", ...], 'pos_train'),\n",
              " (['tbwp', 'is', 'probably', 'the', 'single', 'most', ...], 'pos_train'),\n",
              " (['jonathan', 'demme', \"'\", 's', '_beloved_', ',', ...], 'pos_train'),\n",
              " (['review', ':', 'ghost', 'dog', ':', 'the', 'way', ...], 'pos_train'),\n",
              " (['cinema', 'has', 'been', 'around', 'for', 'about', ...], 'pos_train'),\n",
              " (['synopsis', ':', 'it', \"'\", 's', '1977', 'in', 'a', ...], 'pos_train'),\n",
              " (['as', 'much', 'as', 'i', 'wanted', 'to', 'like', ...], 'pos_train'),\n",
              " (['in', 'may', 'of', '1977', ',', 'just', '2', 'years', ...], 'pos_train'),\n",
              " (['eyes', 'wide', 'shut', 'isn', \"'\", 't', 'the', ...], 'pos_train'),\n",
              " (['at', 'first', 'glance', ',', 'daylight', 'would', ...], 'pos_train'),\n",
              " (['dreamworks', 'pictures', 'presents', 'a', 'jinks', ...], 'pos_train'),\n",
              " (['it', \"'\", 's', 'a', 'fact', 'that', 'a', 'good', ...], 'pos_train'),\n",
              " (['oliver', 'stone', \"'\", 's', 'latest', 'feature', ...], 'pos_train'),\n",
              " (['all', 'those', 'who', 'were', 'offended', 'by', ...], 'pos_train'),\n",
              " (['bruce', 'lee', 'was', 'a', 'bigger', '-', 'than', ...], 'pos_train'),\n",
              " (['when', 'quentin', 'tarantino', 'made', '\"', 'pulp', ...], 'pos_train'),\n",
              " (['robert', 'benton', 'has', 'assembled', 'a', ...], 'pos_train'),\n",
              " (['look', 'back', 'at', 'all', 'the', 'times', 'in', ...], 'pos_train'),\n",
              " (['martin', 'scorsese', \"'\", 's', 'films', 'used', 'to', ...], 'pos_train'),\n",
              " (['the', 'ultimate', 'match', 'up', 'between', 'good', ...], 'pos_train'),\n",
              " (['john', 'cusack', 'is', 'the', 'kind', 'of', 'actor', ...], 'pos_train'),\n",
              " (['it', \"'\", 's', 'rather', 'strange', 'too', 'have', ...], 'pos_train'),\n",
              " (['\"', 'the', 'celebration', '\"', 'is', 'one', 'of', ...], 'pos_train'),\n",
              " (['shakespeare', '.', 'you', 'hardly', 'understood', ...], 'pos_train'),\n",
              " (['hollywood', 'has', 'really', 'done', 'the', 'whole', ...], 'pos_train'),\n",
              " (['with', 'the', 'exception', 'of', 'their', ...], 'pos_train'),\n",
              " (['synopsis', ':', 'in', 'phantom', 'menace', 'the', ...], 'pos_train'),\n",
              " (['there', 'is', 'a', 'striking', 'scene', 'early', ...], 'pos_train'),\n",
              " (['bowfinger', 'is', 'a', 'good', 'movie', 'about', ...], 'pos_train'),\n",
              " (['even', 'if', 'i', 'did', 'not', 'know', 'that', ...], 'pos_train'),\n",
              " (['the', 'thirteenth', 'floor', ',', 'the', 'third', ...], 'pos_train'),\n",
              " (['\"', 'well', 'this', 'is', 'not', 'mission', ':', ...], 'pos_train'),\n",
              " (['edward', 'zwick', \"'\", 's', '\"', 'the', 'siege', '\"', ...], 'pos_train'),\n",
              " (['in', 'tim', 'burton', \"'\", 's', '`', 'sleepy', ...], 'pos_train'),\n",
              " (['capsule', ':', 'bleak', 'and', 'point', '-', 'blank', ...], 'pos_train'),\n",
              " (['you', 'don', \"'\", 't', 'want', 'to', 'be', 'like', ...], 'pos_train'),\n",
              " (['this', 'christmas', ',', 'little', 'ralphie', ...], 'pos_train'),\n",
              " (['when', 'casting', 'the', 'key', 'part', 'of', 'the', ...], 'pos_train'),\n",
              " (['\"', 'oh', 'my', 'god', ',', 'i', 'sounded', 'just', ...], 'pos_train'),\n",
              " (['this', 'british', 'import', 'follows', 'the', '(', ...], 'pos_train'),\n",
              " (['note', ':', 'some', 'may', 'consider', 'portions', ...], 'pos_train'),\n",
              " (['accepting', 'his', 'oscar', 'as', 'producer', 'of', ...], 'pos_train'),\n",
              " (['ingredients', ':', 'starving', 'artist', 'lusting', ...], 'pos_train'),\n",
              " (['the', 'soldiers', 'of', 'three', 'kings', 'have', ...], 'pos_train'),\n",
              " (['now', ',', 'lets', 'first', 'look', 'into', 'the', ...], 'pos_train'),\n",
              " (['in', 'these', 'days', 'of', 'overlong', 'movies', ...], 'pos_train'),\n",
              " (['with', 'the', 'release', 'of', 'gattaca', ',', 'i', ...], 'pos_train'),\n",
              " ([\"'\", 'contact', \"'\", 'shows', 'why', 'jodie', ...], 'pos_train'),\n",
              " (['in', 'roger', 'michell', \"'\", 's', 'romantic', ...], 'pos_train'),\n",
              " (['this', 'sunday', 'afternoon', 'i', 'had', 'the', ...], 'pos_train'),\n",
              " (['earth', 'is', 'a', 'harsh', ',', 'unconsoling', ...], 'pos_train'),\n",
              " (['quentin', 'tarantino', 'seems', 'to', 'have', 'a', ...], 'pos_train'),\n",
              " (['note', ':', 'ordinarily', ',', 'moviereviews', '.', ...], 'pos_train'),\n",
              " (['i', 'had', 'lost', 'all', 'faith', 'in', 'pg', '-', ...], 'pos_train'),\n",
              " (['when', 'i', 'saw', 'the', 'trailer', 'for', 'this', ...], 'pos_train'),\n",
              " (['being', 'the', 'self', '-', 'proclaimed', ...], 'pos_train'),\n",
              " (['no', ',', 'it', 'is', 'not', 'a', 'bad', 'film', ',', ...], 'pos_train'),\n",
              " (['this', 'three', 'hour', 'movie', 'opens', 'up', ...], 'pos_train'),\n",
              " (['i', 'was', 'anxious', 'to', 'see', 'this', 'for', ...], 'pos_train'),\n",
              " (['a', 'standoff', '.', 'a', 'man', 'holds', 'a', ...], 'pos_train'),\n",
              " (['earlier', 'this', 'year', ',', 'the', 'movie', ...], 'pos_train'),\n",
              " (['don', \"'\", 't', 'let', 'the', 'following', 'quirks', ...], 'pos_train'),\n",
              " (['\"', 'psycho', 'meets', 'the', 'exorcist', 'with', ...], 'pos_train'),\n",
              " (['cinematically', 'speaking', ',', 'gordon', 'parks', ...], 'pos_train'),\n",
              " (['jarvis', 'cocker', 'of', 'pulp', 'once', 'said', ...], 'pos_train'),\n",
              " (['what', 'surprises', 'me', 'most', 'about', 'the', ...], 'pos_train'),\n",
              " (['in', '1912', ',', 'a', 'ship', 'set', 'sail', 'on', ...], 'pos_train'),\n",
              " (['written', 'by', 'john', 'grisham', 'and', 'robert', ...], 'pos_train'),\n",
              " (['[', 'note', ':', 'after', 'claiming', 'otherwise', ...], 'pos_train'),\n",
              " (['in', 'intolerance', ',', 'd', '.', 'w', '.', ...], 'pos_train'),\n",
              " (['the', 'film', '\"', 'magnolia', '\"', 'can', 'be', ...], 'pos_train'),\n",
              " (['like', 'the', 'great', 'musical', 'pieces', 'of', ...], 'pos_train'),\n",
              " (['the', 'promotion', 'for', 'fear', 'and', 'loathing', ...], 'pos_train'),\n",
              " (['it', \"'\", 's', 'a', 'curious', 'thing', '-', 'i', ...], 'pos_train'),\n",
              " (['it', \"'\", 's', 'tough', 'to', 'really', 'say', ...], 'pos_train'),\n",
              " (['the', 'question', 'isn', \"'\", 't', 'why', 'has', ...], 'pos_train'),\n",
              " (['perhaps', 'the', 'most', 'dramatic', 'changes', 'in', ...], 'pos_train'),\n",
              " (['uncompromising', 'french', 'director', 'robert', ...], 'pos_train'),\n",
              " (['almost', 'a', 'full', 'decade', 'before', 'steven', ...], 'pos_train'),\n",
              " (['most', 'people', 'fit', 'into', 'two', 'different', ...], 'pos_train'),\n",
              " (['expectation', 'rating', ':', 'a', 'bit', 'worse', ...], 'pos_train'),\n",
              " (['when', 'i', 'first', 'heard', 'about', 'scream', ...], 'pos_train'),\n",
              " (['the', 'muppet', 'movie', 'is', 'the', 'first', ',', ...], 'pos_train'),\n",
              " (['as', 'i', 'walked', 'out', 'of', 'crouching', ...], 'pos_train'),\n",
              " (['it', 'is', 'an', 'understood', 'passion', 'and', ...], 'pos_train'),\n",
              " (['ingredients', ':', 'lost', 'parrot', 'trying', 'to', ...], 'pos_train'),\n",
              " (['in', '\"', 'the', 'sweet', 'hereafter', ',', '\"', ...], 'pos_train'),\n",
              " (['synopsis', ':', 'shrek', '(', 'myers', ')', 'is', ...], 'pos_train'),\n",
              " (['with', 'his', 'last', 'two', 'films', '-', 'shine', ...], 'pos_train'),\n",
              " (['jackie', 'brown', 'entered', 'theaters', 'with', ...], 'pos_train'),\n",
              " (['susan', 'granger', \"'\", 's', 'review', 'of', '\"', ...], 'pos_train'),\n",
              " (['after', 'the', 'terminally', 'bleak', 'reservoir', ...], 'pos_train'),\n",
              " (['synopsis', ':', 'bobby', 'garfield', '(', 'yelchin', ...], 'pos_train'),\n",
              " (['pulp', 'fiction', ',', 'quentin', 'tarantino', \"'\", ...], 'pos_train'),\n",
              " (['in', 'present', 'day', 'hanoi', ',', 'three', ...], 'pos_train'),\n",
              " (['john', 'carpenter', 'directed', 'this', 'stylish', ...], 'pos_train'),\n",
              " (['i', 'can', 'sum', 'up', 'first', 'strike', 'in', ...], 'pos_train'),\n",
              " (['available', 'for', 'rental', '-', 'october', '12', ...], 'pos_train'),\n",
              " (['that', 'thing', 'you', 'do', '!', ',', 'from', ...], 'pos_train'),\n",
              " (['i', 'had', 'a', 'chance', 'to', 'see', 'a', 'sneak', ...], 'pos_train'),\n",
              " (['sometimes', 'a', 'movie', 'comes', 'along', 'that', ...], 'pos_train'),\n",
              " (['with', 'three', 'pre', '-', 'to', 'mid', '-', 'teen', ...], 'pos_train'),\n",
              " (['why', 'do', 'so', 'many', 'children', \"'\", 's', ...], 'pos_train'),\n",
              " (['gothic', 'murder', '-', 'mystery', 'yarns', 'are', ...], 'pos_train'),\n",
              " (['mars', 'attacks', '!', '(', '1996', ')', '-', 'c', ...], 'pos_train'),\n",
              " (['one', 'can', 'not', 'observe', 'a', 'star', 'trek', ...], 'pos_train'),\n",
              " (['when', 'i', 'first', 'heard', 'that', 'disney', \"'\", ...], 'pos_train'),\n",
              " (['much', 'ballyhoo', 'has', 'been', 'made', 'over', ...], 'pos_train'),\n",
              " (['the', 'grandfather', 'of', 'italian', 'horror', ...], 'pos_train'),\n",
              " (['warning', ':', 'anyone', 'offended', 'by', 'blatant', ...], 'pos_train'),\n",
              " (['let', 'me', 'start', 'off', 'by', 'saying', 'that', ...], 'pos_train'),\n",
              " (['in', '1994', ',', 'an', 'insider', \"'\", 's', 'look', ...], 'pos_train'),\n",
              " (['warning', '!', ':', 'may', 'contain', 'some', 'mild', ...], 'pos_train'),\n",
              " (['it', \"'\", 's', 'been', 'a', 'good', 'long', 'while', ...], 'pos_train'),\n",
              " (['when', '_star', 'wars_', 'came', 'out', 'some', ...], 'pos_train'),\n",
              " (['anastasia', 'contains', 'something', 'that', 'has', ...], 'pos_train'),\n",
              " (['wong', 'kar', '-', 'wei', \"'\", 's', '\"', 'fallen', ...], 'pos_train'),\n",
              " (['the', 'opening', 'crawl', 'tells', 'us', 'that', ...], 'pos_train'),\n",
              " (['so', 'many', 'students', 'strive', 'to', 'get', ...], 'pos_train'),\n",
              " (['in', 'the', 'opening', 'shot', 'of', 'midnight', ...], 'pos_train'),\n",
              " (['\"', 'footloose', '\"', 'has', 'only', 'one', 'goal', ...], 'pos_train'),\n",
              " (['it', 'might', 'surprise', 'some', 'to', 'know', ...], 'pos_train'),\n",
              " (['the', 'keen', 'wisdom', 'of', 'an', 'elderly', ...], 'pos_train'),\n",
              " (['richard', 'gere', 'is', 'not', 'one', 'of', 'my', ...], 'pos_train'),\n",
              " (['if', 'the', 'current', 'trends', 'of', 'hollywood', ...], 'pos_train'),\n",
              " (['this', 'has', 'some', 'major', 'spoilers', 'for', ...], 'pos_train'),\n",
              " (['call', 'me', 'crazy', ',', 'but', 'i', 'don', \"'\", ...], 'pos_train'),\n",
              " (['in', '1998', ',', 'director', 'brett', 'ratner', ...], 'pos_train'),\n",
              " (['\"', 'living', 'out', 'loud', ',', '\"', 'is', 'the', ...], 'pos_train'),\n",
              " (['plot', ':', 'derek', 'zoolander', 'is', 'a', 'male', ...], 'pos_train'),\n",
              " (['satirical', 'films', 'usually', 'fall', 'into', ...], 'pos_train'),\n",
              " (['how', 'many', 'of', 'us', 'would', 'become', ...], 'pos_train'),\n",
              " (['who', 'would', 'have', 'thought', '?', 'jim', ...], 'pos_train'),\n",
              " (['one', 'of', 'the', 'funniest', 'carry', 'on', ...], 'pos_train'),\n",
              " (['plot', ':', 'this', 'movie', 'takes', 'place', ...], 'pos_train'),\n",
              " (['in', 'this', 'good', 'natured', ',', 'pleasent', ...], 'pos_train'),\n",
              " (['anna', 'and', 'the', 'king', 'strides', 'onto', ...], 'pos_train'),\n",
              " (['being', 'that', 'it', 'is', 'a', 'foreign', ...], 'pos_train'),\n",
              " (['ingredients', ':', 'man', 'with', 'amnesia', 'who', ...], 'pos_train'),\n",
              " (['time', 'bandits', ',', 'from', 'director', 'terry', ...], 'pos_train'),\n",
              " (['i', \"'\", 'm', 'not', 'quite', 'sure', 'what', 'to', ...], 'pos_train'),\n",
              " (['nosferatu', 'the', 'vampyre', '(', 'germany', '1979', ...], 'pos_train'),\n",
              " (['if', 'you', \"'\", 've', 'ever', 'perused', 'my', ...], 'pos_train'),\n",
              " (['this', 'film', 'is', 'based', 'on', 'the', 'campy', ...], 'pos_train'),\n",
              " (['with', 'the', 'success', 'of', 'the', 'surprise', ...], 'pos_train'),\n",
              " (['very', 'few', 'people', 'would', 'be', 'unaware', ...], 'pos_train'),\n",
              " (['as', 'fairy', 'tales', 'go', ',', 'cinderella', ...], 'pos_train'),\n",
              " (['\"', 'the', 'endurance', ':', 'shackleton', \"'\", 's', ...], 'pos_train'),\n",
              " (['there', \"'\", 's', 'some', 'movies', 'i', 'enjoy', ...], 'pos_train'),\n",
              " (['it', 'has', 'been', 'three', 'long', 'years', ...], 'pos_train'),\n",
              " (['hollywood', 'is', 'a', 'pimp', '.', 'a', 'fat', ',', ...], 'pos_train'),\n",
              " (['kadosh', 'means', 'sacred', 'in', 'hebrew', '.', ...], 'pos_train'),\n",
              " (['i', \"'\", 'll', 'be', 'the', 'first', 'to', 'admit', ...], 'pos_train'),\n",
              " (['we', 'share', 'the', 'descent', 'into', 'darkness', ...], 'pos_train'),\n",
              " (['in', 'december', 'of', '1996', ',', 'a', 'little', ...], 'pos_train'),\n",
              " (['historical', 'epic', 'as', 'a', 'genre', 'was', ...], 'pos_train'),\n",
              " (['after', 'having', 'heard', 'so', 'many', 'critics', ...], 'pos_train'),\n",
              " (['after', 'sixteen', 'years', 'francis', 'ford', ...], 'pos_train'),\n",
              " (['after', 'the', 'press', 'screening', 'of', '\"', ...], 'pos_train'),\n",
              " (['warren', 'beatty', \"'\", 's', '\"', 'bulworth', '\"', ...], 'pos_train'),\n",
              " (['marie', '(', 'charlotte', 'rampling', ',', '\"', ...], 'pos_train'),\n",
              " (['i', 'don', \"'\", 't', 'know', 'how', 'many', 'other', ...], 'pos_train'),\n",
              " (['no', ',', 'i', 'did', 'not', 'read', 'the', 'novel', ...], 'pos_train'),\n",
              " (['this', 'sometimes', '-', 'tedious', 'and', 'often', ...], 'pos_train'),\n",
              " (['near', 'the', 'end', 'of', '1996', ',', 'analysts', ...], 'pos_train'),\n",
              " (['capsule', ':', 'earthy', ',', 'experimental', ',', ...], 'pos_train'),\n",
              " (['the', 'last', 'steve', 'martin', 'film', 'i', 'saw', ...], 'pos_train'),\n",
              " (['one', 'of', 'my', 'colleagues', 'was', 'surprised', ...], 'pos_train'),\n",
              " (['review', '-', 'peter', 'jackson', \"'\", 's', 'the', ...], 'pos_train'),\n",
              " (['synopsis', ':', 'private', 'detective', 'tom', ...], 'pos_train'),\n",
              " (['the', 'bond', 'series', 'is', 'an', 'island', 'in', ...], 'pos_train'),\n",
              " (['director', 'dominic', 'sena', '(', 'who', 'made', ...], 'pos_train'),\n",
              " (['it', 'is', 'easy', 'to', 'label', 'something', ...], 'pos_train'),\n",
              " (['susan', 'granger', \"'\", 's', 'review', 'of', '\"', ...], 'pos_train'),\n",
              " (['i', 'am', 'starting', 'to', 'write', 'this', ...], 'pos_train'),\n",
              " (['a', 'bleak', 'look', 'at', 'how', 'the', 'boston', ...], 'pos_train'),\n",
              " (['when', 'i', 'first', 'heard', 'of', 'contact', ',', ...], 'pos_train'),\n",
              " (['quiz', 'show', ',', 'an', 'almost', 'perfectly', ...], 'pos_train'),\n",
              " (['taking', 'a', 'few', 'tips', 'from', 'the', 'pulp', ...], 'pos_train'),\n",
              " (['note', ':', 'some', 'may', 'consider', 'portions', ...], 'pos_train'),\n",
              " (['blade', 'is', 'the', 'movie', 'that', 'shows', ...], 'pos_train'),\n",
              " (['in', 'zoolander', ',', 'the', 'world', \"'\", 's', ...], 'pos_train'),\n",
              " (['in', 'essence', ',', 'good', 'will', 'hunting', 'is', ...], 'pos_train'),\n",
              " (['*', '*', '*', '*', '*', '*', 'minor', 'plot', ...], 'pos_train'),\n",
              " (['in', 'many', 'ways', ',', '\"', 'twotg', '\"', 'does', ...], 'pos_train'),\n",
              " (['stendhal', \"'\", 's', 'syndrome', ':', 'a', ...], 'pos_train'),\n",
              " (['scream', '2', ',', 'like', 'its', 'predecessor', ',', ...], 'pos_train'),\n",
              " (['the', 'happy', 'bastard', \"'\", 's', 'quick', 'movie', ...], 'pos_train'),\n",
              " (['every', 'once', 'in', 'a', 'while', ',', 'a', 'film', ...], 'pos_train'),\n",
              " (['susan', 'granger', \"'\", 's', 'review', 'of', '\"', ...], 'pos_train'),\n",
              " (['that', \"'\", 's', 'the', 'question', 'i', 'asked', ...], 'pos_train'),\n",
              " (['in', 'the', 'grand', 'scheme', 'of', 'mel', 'gibson', ...], 'pos_train'),\n",
              " (['because', 'the', 'press', 'screening', 'of', '\"', ...], 'pos_train'),\n",
              " (['a', 'movie', 'that', \"'\", 's', 'been', 'as', ...], 'pos_train'),\n",
              " (['it', \"'\", 's', 'no', 'secret', 'in', 'the', 'motion', ...], 'pos_train'),\n",
              " (['while', 'watching', '\"', 'shallow', 'grave', ',', ...], 'pos_train'),\n",
              " (['\"', 'a', 'breed', 'apart', '\"', 'casts', 'rutger', ...], 'pos_train'),\n",
              " (['as', 'the', 'small', 'boats', 'rock', 'slowly', ...], 'pos_train'),\n",
              " (['ingredients', ':', 'neophyte', 'lawyer', ',', ...], 'pos_train'),\n",
              " (['clint', 'eastwood', ',', 'in', 'his', 'ripe', 'old', ...], 'pos_train'),\n",
              " (['no', 'filmmaker', 'deconstructs', 'a', 'story', 'as', ...], 'pos_train'),\n",
              " (['after', 'the', 'simple', 'looking', 'little', ...], 'pos_train'),\n",
              " (['as', 'feel', '-', 'good', 'formulaic', 'as', 'it', ...], 'pos_train'),\n",
              " (['david', 'mamet', 'has', 'long', 'been', 'my', ...], 'pos_train'),\n",
              " (['in', '\"', 'magic', 'town', '\"', ',', 'jimmy', ...], 'pos_train'),\n",
              " (['the', 'happy', 'bastard', \"'\", 's', '30', '-', ...], 'pos_train'),\n",
              " (['i', \"'\", 've', 'always', 'been', 'told', 'that', ...], 'pos_train'),\n",
              " (['the', 'full', 'monty', 'is', 'a', 'whole', 'lot', ...], 'pos_train'),\n",
              " (['i', \"'\", 'm', 'not', 'really', 'sure', 'what', 'to', ...], 'pos_train'),\n",
              " (['when', 'a', 'someone', 'journeys', 'to', 'the', ...], 'pos_train'),\n",
              " (['well', ',', 'i', 'know', 'that', 'stallone', 'is', ...], 'pos_train'),\n",
              " (['star', 'wars', ':', 'episode', '1', '-', 'the', ...], 'pos_train'),\n",
              " (['i', 'rented', 'this', 'movie', 'with', 'very', ...], 'pos_train'),\n",
              " (['i', \"'\", 've', 'noticed', 'something', 'lately', ...], 'pos_train'),\n",
              " (['the', '\"', 'italian', 'hitchcock', '\"', 'and', ...], 'pos_train'),\n",
              " (['three', 'things', 'i', 'learned', 'from', '\"', ...], 'pos_train'),\n",
              " (['warren', 'beatty', 'returns', 'to', 'the', 'screens', ...], 'pos_train'),\n",
              " (['books', 'could', 'be', ',', 'and', 'indeed', 'have', ...], 'pos_train'),\n",
              " (['although', 'many', 'people', 'have', 'compared', ...], 'pos_train'),\n",
              " (['when', 'i', 'saw', 'the', 'trailer', 'for', '\"', ...], 'pos_train'),\n",
              " (['an', 'astonishingly', 'difficult', 'movie', 'to', ...], 'pos_train'),\n",
              " (['the', 'truman', 'show', '(', 'paramount', 'pictures', ...], 'pos_train'),\n",
              " (['luckily', ',', 'some', 'people', 'got', 'starship', ...], 'pos_train'),\n",
              " (['capsule', ':', 'the', 'world', 'will', 'come', 'to', ...], 'pos_train'),\n",
              " (['a', 'costume', 'drama', 'set', 'in', 'the', '1500s', ...], 'pos_train'),\n",
              " (['note', ':', 'some', 'may', 'consider', 'portions', ...], 'pos_train'),\n",
              " (['plot', ':', 'a', 'human', 'space', 'astronaut', ...], 'pos_train'),\n",
              " (['with', 'the', 'sudden', 'liberal', 'emergence', 'of', ...], 'pos_train'),\n",
              " (['losing', 'a', 'job', 'is', 'not', 'an', 'all', 'too', ...], 'pos_train'),\n",
              " (['modern', 'audiences', 'are', 'more', 'likely', 'to', ...], 'pos_train'),\n",
              " (['i', 'had', 'been', 'expecting', 'more', 'of', 'this', ...], 'pos_train'),\n",
              " (['mickey', 'mouse', 'had', 'better', 'watch', 'his', ...], 'pos_train'),\n",
              " (['it', 'has', 'happened', 'again', '.', 'a', 'movie', ...], 'pos_train'),\n",
              " (['when', 'i', 'first', 'saw', 'the', 'previews', 'for', ...], 'pos_train'),\n",
              " (['it', 'has', 'been', '20', 'years', 'since', 'a', ...], 'pos_train'),\n",
              " (['\"', 'seven', '\"', 'is', 'one', 'of', 'the', 'best', ...], 'pos_train'),\n",
              " (['whenever', 'writer', '/', 'director', 'robert', ...], 'pos_train'),\n",
              " (['richard', 'gere', 'can', 'be', 'a', 'commanding', ...], 'pos_train'),\n",
              " (['when', 'i', 'first', 'heard', 'that', 'kevin', ...], 'pos_train'),\n",
              " (['\"', 'jaws', '\"', 'is', 'a', 'rare', 'film', 'that', ...], 'pos_train'),\n",
              " (['insane', '(', 'but', 'inspired', ')', 'musical', ...], 'pos_train'),\n",
              " (['not', 'too', 'many', 'people', 'know', 'who', ...], 'pos_train'),\n",
              " (['us', 'critic', '-', 'type', 'people', 'are', ...], 'pos_train'),\n",
              " (['my', 'summer', 'was', 'recently', 'saved', 'by', ...], 'pos_train'),\n",
              " (['this', 'is', 'a', 'film', 'about', 'secrets', ',', ...], 'pos_train'),\n",
              " (['while', 'alex', 'browning', '(', 'devon', 'sawa', ...], 'pos_train'),\n",
              " (['i', 'think', 'the', 'first', 'thing', 'this', ...], 'pos_train'),\n",
              " (['the', 'calendar', 'year', 'has', 'not', 'even', ...], 'pos_train'),\n",
              " (['\"', 'it', \"'\", 's', 'not', 'good', 'to', 'know', ...], 'pos_train'),\n",
              " (['>', 'from', 'the', 'man', 'who', 'presented', 'us', ...], 'pos_train'),\n",
              " (['i', 'love', 'this', 'movie', ',', 'and', 'i', \"'\", ...], 'pos_train'),\n",
              " (['not', 'since', '1996', \"'\", 's', 'shine', ',', ...], 'pos_train'),\n",
              " (['unzipped', 'is', 'a', 'cinematic', 'portrait', 'of', ...], 'pos_train'),\n",
              " (['one', 'of', 'the', 'best', 'things', 'about', 'my', ...], 'pos_train'),\n",
              " (['contrary', 'to', 'the', 'title', ',', '\"', 'the', ...], 'pos_train'),\n",
              " (['krippendorf', \"'\", 's', 'tribe', 'is', 'a', ...], 'pos_train'),\n",
              " (['eddie', 'murphy', 'has', 'had', 'his', 'share', 'of', ...], 'pos_train'),\n",
              " (['just', 'look', 'back', 'two', 'years', 'ago', 'at', ...], 'pos_train'),\n",
              " (['i', 'wish', 'i', 'could', 'say', 'that', 'there', ...], 'pos_train'),\n",
              " (['national', 'lampoon', \"'\", 's', 'animal', 'house', ...], 'pos_train'),\n",
              " (['matthew', 'broderick', 'and', 'high', 'school', ...], 'pos_train'),\n",
              " (['i', 'want', 'to', 'correct', 'what', 'i', 'wrote', ...], 'pos_train'),\n",
              " (['hedwig', '(', 'john', 'cameron', 'mitchell', ')', ...], 'pos_train'),\n",
              " (['after', 'the', 'average', 'mouse', 'hunt', ',', ...], 'pos_train'),\n",
              " (['review', ':', 'a', 'dog', 'of', 'flanders', 'is', ...], 'pos_train'),\n",
              " (['hollywood', 'has', 'a', '.', '750', 'batting', ...], 'pos_train'),\n",
              " (['while', 'watching', 'boiler', 'room', ',', 'i', ...], 'pos_train'),\n",
              " (['it', \"'\", 's', 'an', 'interesting', 'premise', '.', ...], 'pos_train'),\n",
              " (['\"', 'no', 'man', 'is', 'an', 'island', ',', '\"', ...], 'pos_train'),\n",
              " (['the', 'year', 'is', '1962', 'and', 'the', 'military', ...], 'pos_train'),\n",
              " (['after', 'a', 'successful', 'run', 'in', 'australia', ...], 'pos_train'),\n",
              " (['naturally', ',', 'at', 'the', 'core', 'of', 'leon', ...], 'pos_train'),\n",
              " (['if', 'you', 'thought', 'baz', 'luhrmann', \"'\", 's', ...], 'pos_train'),\n",
              " (['did', 'claus', 'von', 'bulow', 'try', 'to', 'kill', ...], 'pos_train'),\n",
              " (['susan', 'granger', \"'\", 's', 'review', 'of', '\"', ...], 'pos_train'),\n",
              " (['city', 'of', 'angels', 'is', 'the', 'kind', 'of', ...], 'pos_train'),\n",
              " (['no', ',', 'it', 'is', 'not', 'a', 'bad', 'film', ',', ...], 'pos_train'),\n",
              " (['every', 'once', 'in', 'a', 'while', ',', 'when', ...], 'pos_train'),\n",
              " (['plot', ':', 'a', 'peculiar', 'french', 'girl', ...], 'pos_train'),\n",
              " (['in', 'brief', ':', 'best', 'bleak', 'comedy', 'film', ...], 'pos_train'),\n",
              " (['set', 'in', 'the', 'wild', 'west', ',', 'this', ...], 'pos_train'),\n",
              " (['you', \"'\", 've', 'got', 'to', 'think', 'twice', ...], 'pos_train'),\n",
              " (['the', 'ring', 'is', 'probably', 'one', 'of', 'the', ...], 'pos_train'),\n",
              " (['jay', 'and', 'silent', 'bob', 'strike', 'back', ...], 'pos_train'),\n",
              " (['\"', 'very', 'bad', 'things', ',', '\"', 'is', 'the', ...], 'pos_train'),\n",
              " (['he', 'has', 'spent', 'his', 'entire', 'life', 'in', ...], 'pos_train'),\n",
              " (['for', 'the', 'first', 'reel', 'of', 'girls', 'town', ...], 'pos_train'),\n",
              " (['in', '1995', ',', 'brian', 'singer', 'and', ...], 'pos_train'),\n",
              " (['capsule', ':', 'this', 'is', 'a', 'film', 'that', ...], 'pos_train'),\n",
              " (['i', 'recall', 'the', 'trials', 'and', 'tribulations', ...], 'pos_train'),\n",
              " (['john', 'sayles', \"'\", '\"', 'men', 'with', 'guns', ...], 'pos_train'),\n",
              " (['\"', 'the', 'fugitive', '\"', 'is', 'probably', 'one', ...], 'pos_train'),\n",
              " (['playwright', 'tom', 'stoppard', 'and', ...], 'pos_train'),\n",
              " (['ever', 'wonder', 'what', 'happened', 'to', 'gabe', ...], 'pos_train'),\n",
              " (['bob', 'the', 'happy', 'bastard', \"'\", 's', 'quickie', ...], 'pos_train'),\n",
              " (['the', 'idea', 'at', 'the', 'center', 'of', 'the', ...], 'pos_train'),\n",
              " (['i', 'suppose', 'an', 'argument', 'could', 'be', ...], 'pos_train'),\n",
              " (['in', '1987', 'the', 'stock', 'market', 'crashed', ...], 'pos_train'),\n",
              " (['one', 'of', 'kyle', 'mclachlan', \"'\", 's', 'earlier', ...], 'pos_train'),\n",
              " (['towards', 'the', 'middle', 'of', '\"', 'the', 'sweet', ...], 'pos_train'),\n",
              " (['roberto', 'benigni', 'is', 'a', 'clown', 'in', 'the', ...], 'pos_train'),\n",
              " (['since', 'their', 'film', 'debut', 'in', '1984', ...], 'pos_train'),\n",
              " (['studio', 'expectations', 'must', 'not', 'have', ...], 'pos_train'),\n",
              " (['jean', '-', 'luc', 'picard', '(', 'patrick', ...], 'pos_train'),\n",
              " (['seen', 'may', '31', ',', '1999', 'on', 'home', ...], 'pos_train'),\n",
              " (['seen', 'september', '13', ',', '1998', 'at', '4', ...], 'pos_train'),\n",
              " (['hilarious', ',', 'ultra', '-', 'low', 'budget', ...], 'pos_train'),\n",
              " (['a', 'sci', 'fi', '/', 'comedy', 'starring', 'jack', ...], 'pos_train'),\n",
              " (['i', 'can', 'already', 'feel', 'the', 'hate', ...], 'pos_train'),\n",
              " (['the', 'start', 'of', 'this', 'movie', 'reminded', ...], 'pos_train'),\n",
              " (['\"', 'when', 'will', 'the', 'devil', 'take', 'me', ...], 'pos_train'),\n",
              " (['apollo', '13', 'is', 'simply', 'one', 'of', 'the', ...], 'pos_train'),\n",
              " (['one', 'of', 'the', 'sweetest', 'tales', 'to', 'ever', ...], 'pos_train'),\n",
              " (['it', \"'\", 's', 'been', 'a', 'long', 'time', 'since', ...], 'pos_train'),\n",
              " (['felix', '(', 'sami', 'bouajila', ',', '\"', 'the', ...], 'pos_train'),\n",
              " (['seen', 'april', '16', ',', '1999', 'at', '10', 'p', ...], 'pos_train'),\n",
              " (['zero', 'effect', 'gets', 'its', 'title', 'from', ...], 'pos_train'),\n",
              " (['the', 'thought', '-', 'provoking', 'question', 'of', ...], 'pos_train'),\n",
              " (['the', 'caveman', \"'\", 's', 'valentine', 'starring', ...], 'pos_train'),\n",
              " (['wow', '!', 'what', 'a', 'movie', '.', 'it', \"'\", 's', ...], 'pos_train'),\n",
              " (['kirk', 'douglas', 'is', 'one', 'of', 'those', 'rare', ...], 'pos_train'),\n",
              " (['`', 'strange', 'days', \"'\", 'chronicles', 'the', ...], 'pos_train'),\n",
              " (['have', 'you', 'ever', 'wondered', 'if', 'death', ...], 'pos_train'),\n",
              " (['after', 'watching', '\"', 'rat', 'race', '\"', 'last', ...], 'pos_train'),\n",
              " (['at', 'first', 'glance', ',', 'it', 'appears', 'that', ...], 'pos_train'),\n",
              " (['meet', 'joe', 'black', '(', 'reviewed', 'on', 'nov', ...], 'pos_train'),\n",
              " (['i', 'want', 'to', 'correct', 'what', 'i', 'wrote', ...], 'pos_train'),\n",
              " (['\"', 'the', 'faculty', ',', '\"', 'the', 'heavily', ...], 'pos_train'),\n",
              " (['to', 'me', ',', 'nicolas', 'cage', 'sounds', 'like', ...], 'pos_train'),\n",
              " (['plot', ':', 'good', 'ol', \"'\", 'texan', 'kid', ...], 'pos_train'),\n",
              " (['the', 'andromeda', 'strain', 'is', 'the', 'greatest', ...], 'pos_train'),\n",
              " (['i', 'have', 'seen', 'several', '(', 'but', 'not', ...], 'pos_train'),\n",
              " (['leonardo', 'decaprio', '(', 'what', \"'\", 's', ...], 'pos_train'),\n",
              " (['it', \"'\", 's', 'hard', 'not', 'to', 'recommend', '\"', ...], 'pos_train'),\n",
              " (['vampire', 'films', ',', 'as', 'well', 'as', 'other', ...], 'pos_train'),\n",
              " (['it', \"'\", 's', 'ironic', 'that', 'the', 'best', ...], 'pos_train'),\n",
              " (['until', 'i', 'saw', 'the', 'night', 'of', 'the', ...], 'pos_train'),\n",
              " (['david', 'lynch', \"'\", 's', '\"', 'blue', 'velvet', ...], 'pos_train'),\n",
              " (['what', \"'\", 's', 'shocking', 'about', '\"', 'carlito', ...], 'pos_train'),\n",
              " (['usually', 'when', 'a', 'blockbuster', 'comes', 'out', ...], 'pos_train'),\n",
              " (['vannesa', 'kensington', ':', '`', 'austin', ',', ...], 'pos_train'),\n",
              " (['the', 'premise', 'is', 'simple', ',', 'if', 'not', ...], 'pos_train'),\n",
              " (['when', 'i', 'was', 'growing', 'up', 'in', '1970s', ...], 'pos_train'),\n",
              " (['first', ',', 'i', 'am', 'not', 'a', 'big', 'fan', ...], 'pos_train'),\n",
              " (['capsule', ':', 'a', 'short', 'punchy', 'action', ...], 'pos_train'),\n",
              " (['if', 'you', \"'\", 're', 'the', 'type', 'of', 'person', ...], 'pos_train'),\n",
              " (['there', 'are', 'some', 'works', 'of', 'art', 'that', ...], 'pos_train'),\n",
              " (['based', 'on', 'the', 'boris', 'karloff', \"'\", 's', ...], 'pos_train'),\n",
              " (['in', 'the', 'wake', 'of', 'the', 'smashing', ...], 'pos_train'),\n",
              " (['on', 'june', '30', ',', '1960', ',', 'a', 'self', ...], 'pos_train'),\n",
              " (['disney', 'cements', 'their', 'place', 'in', 'the', ...], 'pos_train'),\n",
              " (['october', 'sky', 'is', 'a', 'rare', 'oddity', 'in', ...], 'pos_train'),\n",
              " (['the', 'coen', 'brothers', 'are', 'back', 'again', ...], 'pos_train'),\n",
              " (['before', 'even', 'seeing', 'a', 'single', 'frame', ...], 'pos_train'),\n",
              " (['if', 'there', \"'\", 's', 'one', 'thing', 'in', ...], 'pos_train'),\n",
              " (['note', ':', 'some', 'may', 'consider', 'portions', ...], 'pos_train'),\n",
              " (['another', \"'\", 'independent', 'film', \"'\", ',', ...], 'pos_train'),\n",
              " (['\"', 'rebel', 'without', 'a', 'cause', '\"', 'is', ...], 'pos_train'),\n",
              " (['ingredients', ':', 'james', 'bond', ',', 'scuba', ...], 'pos_train'),\n",
              " (['probably', 'the', 'most', 'popular', 'and', ...], 'pos_train'),\n",
              " (['note', ':', 'some', 'may', 'consider', 'portions', ...], 'pos_train'),\n",
              " (['titanic', 'is', 'so', 'close', 'to', 'being', 'the', ...], 'pos_train'),\n",
              " (['just', 'how', 'inseparable', 'is', 'the', 'team', ...], 'pos_train'),\n",
              " (['armageddon', ',', 'in', 'itself', ',', 'symbolizes', ...], 'pos_train'),\n",
              " (['okay', ',', 'let', 'me', 'first', 'say', ',', 'this', ...], 'pos_train'),\n",
              " (['steven', 'spielberg', \"'\", 's', '\"', 'amistad', ',', ...], 'pos_train'),\n",
              " (['usually', 'a', 'movie', 'is', 'about', 'something', ...], 'pos_train'),\n",
              " (['truman', '(', '\"', 'true', '-', 'man', '\"', ')', ...], 'pos_train'),\n",
              " (['this', 'is', 'the', 'best', 'british', 'gangster', ...], 'pos_train'),\n",
              " (['the', 'summer', 'movie', 'season', 'is', 'always', ...], 'pos_train'),\n",
              " (['--', 'comedy', ',', 'rated', 'pg', ',', 'runs', ...], 'pos_train'),\n",
              " (['finding', 'the', 'courage', 'to', 'face', 'life', ...], 'pos_train'),\n",
              " (['imagine', 'this', '.', 'you', \"'\", 're', 'given', ...], 'pos_train'),\n",
              " (['a', 'wonderful', 'little', 'movie', 'that', 'is', ...], 'pos_train'),\n",
              " (['for', 'many', 'people', ',', 'procrastination', ...], 'pos_train'),\n",
              " (['a', 'lot', 'of', 'times', 'a', 'three', '-', 'star', ...], 'pos_train'),\n",
              " (['as', 'any', 'sociologist', 'will', 'attest', ',', ...], 'pos_train'),\n",
              " (['note', ':', 'some', 'may', 'consider', 'portions', ...], 'pos_train'),\n",
              " (['airplane', '!', 'is', 'considered', 'among', 'many', ...], 'pos_train'),\n",
              " (['bob', 'the', 'happy', 'bastard', \"'\", 's', 'quickie', ...], 'pos_train'),\n",
              " (['many', 'people', 'will', 'not', 'find', 'much', 'to', ...], 'pos_train'),\n",
              " (['garry', 'shandling', 'makes', 'his', 'long', ...], 'pos_train'),\n",
              " (['note', ':', 'some', 'may', 'consider', 'portions', ...], 'pos_train'),\n",
              " (['the', 'booming', 'introduction', 'music', 'finishes', ...], 'pos_train'),\n",
              " (['there', \"'\", 's', 'good', 'news', 'and', 'bad', ...], 'pos_train'),\n",
              " (['pollock', 'starring', 'ed', 'harris', ',', 'marcia', ...], 'pos_train'),\n",
              " (['imagine', 'this', 'scenario', ':', 'you', 'and', ...], 'pos_train'),\n",
              " (['after', 'bloody', 'clashes', 'and', 'independence', ...], 'pos_train'),\n",
              " (['there', \"'\", 's', 'an', 'old', 'saying', 'that', ...], 'pos_train'),\n",
              " (['carolco', 'pictures', 'and', 'dutch', 'director', ...], 'pos_train'),\n",
              " (['catherine', 'deane', '(', 'jennifer', 'lopez', ')', ...], 'pos_train'),\n",
              " (['that', 'thing', 'you', 'do', '!', '(', 'r', ')', ...], 'pos_train'),\n",
              " (['casting', '\"', 'doogie', 'howser', '\"', 'star', ...], 'pos_train'),\n",
              " (['as', 'with', 'his', 'other', 'stateside', 'releases', ...], 'pos_train'),\n",
              " (['quaid', 'stars', 'as', 'a', 'man', 'who', 'has', ...], 'pos_train'),\n",
              " (['bill', 'condon', \"'\", 's', '\"', 'gods', 'and', ...], 'pos_train'),\n",
              " (['i', 'don', \"'\", 't', 'box', 'with', 'kid', 'gloves', ...], 'pos_train'),\n",
              " (['after', 'being', 'hypnotized', ',', 'a', 'man', ...], 'pos_train'),\n",
              " (['what', 'i', 'look', 'for', 'in', 'a', 'movie', 'is', ...], 'pos_train'),\n",
              " (['albert', 'brooks', 'saves', 'the', 'day', ',', ...], 'pos_train'),\n",
              " (['susan', 'granger', \"'\", 's', 'review', 'of', '\"', ...], 'pos_train'),\n",
              " (['the', '1990s', 'produced', 'two', 'brilliant', ...], 'pos_train'),\n",
              " (['there', 'was', 'a', 'huge', 'crowd', '-', 'so', ...], 'pos_train'),\n",
              " (['one', 'of', 'the', 'most', 'popular', 'subplots', ...], 'pos_train'),\n",
              " (['as', 'a', 'devout', 'atheist', 'and', 'an', 'avowed', ...], 'pos_train'),\n",
              " (['your', 'first', 'clue', 'that', 'something', 'isn', ...], 'neg_train'),\n",
              " (['violence', 'is', 'bad', '.', 'violence', 'is', ...], 'neg_train'),\n",
              " (['the', 'happy', 'bastard', \"'\", 's', 'quick', 'movie', ...], 'neg_train'),\n",
              " (['the', 'recent', 'onslaught', 'of', 'film', 'noir', ...], 'neg_train'),\n",
              " (['capsule', ':', 'where', 'are', 'you', 'tonight', ',', ...], 'neg_train'),\n",
              " (['after', 'the', 'huge', 'success', 'of', '\"', 'the', ...], 'neg_train'),\n",
              " (['where', 'do', 'i', 'begin', '?', 'okay', ',', 'how', ...], 'neg_train'),\n",
              " (['\"', 'the', 'red', 'violin', '\"', 'is', 'a', 'cold', ...], 'neg_train'),\n",
              " (['an', '80', '-', 'year', 'old', 'woman', 'jumps', ...], 'neg_train'),\n",
              " (['these', 'days', ',', 'people', 'have', 'rather', ...], 'neg_train'),\n",
              " (['saw', 'an', 'advanced', 'screening', 'of', 'the', ...], 'neg_train'),\n",
              " (['keep', 'cool', ',', 'a', 'chinese', 'film', ...], 'neg_train'),\n",
              " (['\"', 'deep', 'rising', '\"', 'gives', 'you', 'that', ...], 'neg_train'),\n",
              " (['any', 'movie', 'that', 'kills', 'emilio', 'estevez', ...], 'neg_train'),\n",
              " (['capsule', ':', 'the', 'much', 'anticipated', 're', ...], 'neg_train'),\n",
              " (['i', 'have', 'always', 'been', 'a', 'fan', 'of', ...], 'neg_train'),\n",
              " (['yet', 'another', 'brainless', 'teen', 'flick', ',', ...], 'neg_train'),\n",
              " (['\"', 'in', 'dreams', '\"', 'might', 'keep', 'you', ...], 'neg_train'),\n",
              " (['the', 'scene', 'at', 'the', 'end', 'of', '1989', \"'\", ...], 'neg_train'),\n",
              " (['synopsis', ':', 'a', 'maniac', ',', 'crazed', 'by', ...], 'neg_train'),\n",
              " (['post', '-', 'chasing', 'amy', ',', 'a', 'slew', 'of', ...], 'neg_train'),\n",
              " (['synopsis', ':', 'two', 'con', 'artists', 'find', ...], 'neg_train'),\n",
              " (['what', 'happens', 'when', 'you', 'put', 'martin', ...], 'neg_train'),\n",
              " (['for', 'timing', 'reasons', 'having', 'to', 'do', ...], 'neg_train'),\n",
              " (['plot', ':', 'a', 'young', 'french', 'boy', 'sees', ...], 'neg_train'),\n",
              " (['it', 'is', 'with', 'some', 'sad', 'irony', 'that', ...], 'neg_train'),\n",
              " (['conventional', 'wisdom', 'among', 'collectibles', ...], 'neg_train'),\n",
              " (['\"', 'nothing', 'more', 'than', 'a', 'high', 'budget', ...], 'neg_train'),\n",
              " (['filmmakers', 'will', 'use', 'all', 'manner', 'of', ...], 'neg_train'),\n",
              " (['you', 'think', 'that', 'these', 'people', 'only', ...], 'neg_train'),\n",
              " (['the', 'most', 'depressing', 'thing', 'about', 'the', ...], 'neg_train'),\n",
              " (['in', 'double', 'jeopardy', ',', 'the', 'stakes', ...], 'neg_train'),\n",
              " (['i', \"'\", 'll', 'bet', 'right', 'now', 'you', \"'\", ...], 'neg_train'),\n",
              " (['depending', 'on', 'your', 'degree', 'of', ...], 'neg_train'),\n",
              " (['in', '\"', 'twilight', ',', '\"', 'a', 'ex', '-', ...], 'neg_train'),\n",
              " (['and', 'just', 'when', 'you', 'thought', 'joblo', ...], 'neg_train'),\n",
              " (['a', 'hotshot', 'lawyer', 'gets', 'an', 'obviously', ...], 'neg_train'),\n",
              " (['capsule', ':', 'john', 'the', 'baptist', 'is', ...], 'neg_train'),\n",
              " (['phil', '(', 'radmar', 'jao', ')', 'has', 'a', ...], 'neg_train'),\n",
              " (['gun', 'wielding', 'arnold', 'schwarzenegger', 'has', ...], 'neg_train'),\n",
              " (['plot', ':', 'token', 'director', 'alan', 'smithee', ...], 'neg_train'),\n",
              " (['by', 'starring', 'in', 'amy', 'heckerling', \"'\", 's', ...], 'neg_train'),\n",
              " (['david', 'schwimmer', '(', 'from', 'the', ...], 'neg_train'),\n",
              " (['i', 'came', 'to', 'an', 'epiphany', 'while', ...], 'neg_train'),\n",
              " (['_dirty_work_', 'has', 'a', 'premise', 'of', ...], 'neg_train'),\n",
              " (['maybe', 'this', 'mission', 'should', 'have', 'been', ...], 'neg_train'),\n",
              " (['you', 'don', \"'\", 't', 'look', 'at', 'a', 'ren', '?', ...], 'neg_train'),\n",
              " (['capsule', ':', 'one', 'of', 'the', 'ten', 'worst', ...], 'neg_train'),\n",
              " (['to', 'sum', 'the', 'entire', 'film', '\"', '54', '\"', ...], 'neg_train'),\n",
              " (['boy', ',', 'what', 'a', 'great', 'movie', '!', '!', ...], 'neg_train'),\n",
              " (['john', 'boorman', \"'\", 's', '\"', 'zardoz', '\"', 'is', ...], 'neg_train'),\n",
              " (['some', 'movies', 'require', 'you', 'to', 'turn', ...], 'neg_train'),\n",
              " (['movie', 'reviewers', 'have', 'an', 'obligation', ...], 'neg_train'),\n",
              " (['there', 'was', 'probably', 'a', 'good', 'reason', ...], 'neg_train'),\n",
              " (['the', 'tagline', 'for', 'this', 'film', 'is', ':', ...], 'neg_train'),\n",
              " (['senseless', '(', 'r', ')', 'marlon', 'wayans', 'is', ...], 'neg_train'),\n",
              " (['attention', 'moviegoers', ':', 'you', 'are', 'about', ...], 'neg_train'),\n",
              " (['my', 'son', 'and', 'i', 'share', 'a', 'perverse', ...], 'neg_train'),\n",
              " (['last', 'summer', ',', 'a', 'feature', '-', 'length', ...], 'neg_train'),\n",
              " (['\"', '.', '.', '.', 'because', 'i', \"'\", 'm', 'a', ...], 'neg_train'),\n",
              " (['i', 'heard', 'actor', 'skeet', 'ulrich', ...], 'neg_train'),\n",
              " (['this', 'is', 'not', 'a', 'simple', 'plan', 'about', ...], 'neg_train'),\n",
              " (['senseless', 'is', 'a', 'prime', 'example', 'of', ...], 'neg_train'),\n",
              " (['absolute', 'power', ',', 'the', 'new', 'film', ...], 'neg_train'),\n",
              " (['alexander', 'dumas', \"'\", 'the', 'three', ...], 'neg_train'),\n",
              " (['fit', 'for', 'a', 'ghoul', \"'\", 's', 'night', 'out', ...], 'neg_train'),\n",
              " (['although', 'i', 'had', 'not', 'been', 'a', 'viewer', ...], 'neg_train'),\n",
              " (['not', 'a', 'great', 'twelve', 'months', 'for', ...], 'neg_train'),\n",
              " (['has', 'hollywood', 'run', 'out', 'of', 'interesting', ...], 'neg_train'),\n",
              " (['hong', 'kong', 'cinema', 'has', 'been', 'going', ...], 'neg_train'),\n",
              " (['miramax', '\"', 'disinvited', '\"', 'on', '-', 'line', ...], 'neg_train'),\n",
              " (['new', 'address', '.', 'same', 'old', 'attitude', '.', ...], 'neg_train'),\n",
              " (['hello', 'kids', '.', 'today', 'the', 'movie', ...], 'neg_train'),\n",
              " (['in', 'french', ',', 'the', 'phrase', '\"', 'film', ...], 'neg_train'),\n",
              " (['the', 'haunting', ',', 'a', 'film', 'so', ...], 'neg_train'),\n",
              " (['godzilla', 'is', 'the', 'ultimate', 'culmination', ...], 'neg_train'),\n",
              " (['capsule', ':', 'liebes', 'meets', 'tod', '.', 'this', ...], 'neg_train'),\n",
              " (['gregg', 'araki', \"'\", 's', 'the', 'doom', ...], 'neg_train'),\n",
              " (['\"', 'jack', 'frost', ',', '\"', 'is', 'one', 'of', ...], 'neg_train'),\n",
              " (['retelling', 'the', 'classic', 'story', 'of', 'joan', ...], 'neg_train'),\n",
              " (['if', 'anyone', 'had', 'been', 'able', 'in', '1983', ...], 'neg_train'),\n",
              " (['i', \"'\", 'm', 'not', 'sure', 'if', 'silvio', 'horta', ...], 'neg_train'),\n",
              " (['this', 'is', 'the', 'worst', 'movie', 'i', \"'\", 've', ...], 'neg_train'),\n",
              " (['my', 'first', 'exposure', 'to', 'the', 'nightmare', ...], 'neg_train'),\n",
              " (['everything', 'about', 'this', 'ninth', 'trek', ...], 'neg_train'),\n",
              " (['\"', 'be', 'gentle', ',', '\"', 'urges', 'natasha', ...], 'neg_train'),\n",
              " (['i', 'went', 'to', 'blair', 'witch', 'project', '2', ...], 'neg_train'),\n",
              " (['it', \"'\", 's', 'time', 'to', 'take', 'cover', '.', ...], 'neg_train'),\n",
              " (['this', 'feature', 'is', 'like', 'a', 'double', ...], 'neg_train'),\n",
              " (['note', ':', 'some', 'may', 'consider', 'portions', ...], 'neg_train'),\n",
              " (['a', 'couple', 'of', 'criminals', '(', 'mario', 'van', ...], 'neg_train'),\n",
              " (['here', \"'\", 's', 'a', 'rarity', ':', 'a', 'children', ...], 'neg_train'),\n",
              " (['it', \"'\", 's', 'amazing', 'how', 'a', 'comedian', ...], 'neg_train'),\n",
              " (['if', 'you', \"'\", 've', 'seen', 'the', 'trailers', ...], 'neg_train'),\n",
              " (['when', 'the', 'haunting', 'arrived', 'in', ...], 'neg_train'),\n",
              " (['house', 'on', 'haunted', 'hill', '(', '1999', ')', ...], 'neg_train'),\n",
              " (['long', 'ago', ',', 'films', 'were', 'constructed', ...], 'neg_train'),\n",
              " (['i', 'love', 'movies', '.', 'i', 'really', 'do', '.', ...], 'neg_train'),\n",
              " (['well', 'if', 'you', 'are', 'up', 'for', 'stellar', ...], 'neg_train'),\n",
              " (['a', 'life', 'less', 'ordinary', '(', 'r', ')', ...], 'neg_train'),\n",
              " (['paul', 'verhoeven', ',', 'the', 'dutch', 'auteur', ...], 'neg_train'),\n",
              " (['\"', 'tina', '!', '!', '!', 'fetch', 'me', 'the', ...], 'neg_train'),\n",
              " (['well', ',', 'here', \"'\", 's', 'a', 'distasteful', ...], 'neg_train'),\n",
              " (['it', 'would', 'be', 'hard', 'to', 'choose', 'the', ...], 'neg_train'),\n",
              " (['mr', '.', 'bean', ',', 'a', 'bumbling', 'security', ...], 'neg_train'),\n",
              " (['stars', ':', 'armand', 'assante', '(', 'mike', ...], 'neg_train'),\n",
              " (['silly', 'performances', 'and', 'some', 'huge', ...], 'neg_train'),\n",
              " (['the', 'job', 'of', 'the', 'film', 'critic', 'is', ...], 'neg_train'),\n",
              " (['a', 'movie', 'like', 'mortal', 'kombat', ':', ...], 'neg_train'),\n",
              " (['\"', 'have', 'you', 'ever', 'heard', 'the', 'one', ...], 'neg_train'),\n",
              " (['like', 'a', 'good', 'action', 'film', 'should', ',', ...], 'neg_train'),\n",
              " (['the', 'law', 'of', 'crowd', 'pleasing', 'romantic', ...], 'neg_train'),\n",
              " (['for', 'those', 'interested', 'in', 'the', 'true', ...], 'neg_train'),\n",
              " (['if', 'there', 'were', 'a', 'subject', 'just', ...], 'neg_train'),\n",
              " (['arye', 'cross', 'and', 'courteney', 'cox', 'star', ...], 'neg_train'),\n",
              " (['i', 'think', 'of', 'i', 'know', 'what', 'you', 'did', ...], 'neg_train'),\n",
              " (['deserves', 'recognition', 'for', ':', 'making', ...], 'neg_train'),\n",
              " (['bad', 'movies', 'described', 'as', '\"', 'a', 'swift', ...], 'neg_train'),\n",
              " (['let', \"'\", 's', 'get', 'this', 'one', 'over', 'with', ...], 'neg_train'),\n",
              " (['the', 'event', 'horizon', 'is', 'the', 'boundary', ...], 'neg_train'),\n",
              " (['this', 'is', 'the', 'last', 'carry', 'on', 'film', ...], 'neg_train'),\n",
              " (['susan', 'granger', \"'\", 's', 'review', 'of', '\"', ...], 'neg_train'),\n",
              " (['\"', 'the', '13th', 'warrior', '\"', 'comes', 'at', ...], 'neg_train'),\n",
              " (['young', 'einstein', 'is', 'embarrassingly', 'lame', ...], 'neg_train'),\n",
              " (['several', 'days', 'after', 'having', 'seen', 'this', ...], 'neg_train'),\n",
              " (['adam', 'sandler', 'vehicles', 'are', 'never', ...], 'neg_train'),\n",
              " (['edward', 'burns', 'tackles', 'his', 'third', ...], 'neg_train'),\n",
              " (['susan', 'granger', \"'\", 's', 'review', 'of', '\"', ...], 'neg_train'),\n",
              " (['look', '!', 'the', 'new', 'version', 'of', '\"', ...], 'neg_train'),\n",
              " (['as', 'bad', 'as', '\"', 'mimic', '\"', 'was', ',', ...], 'neg_train'),\n",
              " (['susan', 'granger', \"'\", 's', 'review', 'of', '\"', ...], 'neg_train'),\n",
              " (['the', 'best', 'thing', 'about', ',', '\"', 'lake', ...], 'neg_train'),\n",
              " (['of', 'course', 'i', 'knew', 'this', 'going', 'in', ...], 'neg_train'),\n",
              " (['if', 'you', \"'\", 've', 'been', 'following', ...], 'neg_train'),\n",
              " (['in', '\"', 'the', '13th', 'warrior', ',', '\"', 'arab', ...], 'neg_train'),\n",
              " (['about', 'an', 'hour', 'or', 'so', 'into', '\"', 'the', ...], 'neg_train'),\n",
              " (['burnt', 'money', 'is', 'the', 'perfect', 'festival', ...], 'neg_train'),\n",
              " (['around', 'the', 'end', 'of', '1998', ',', 'a', ...], 'neg_train'),\n",
              " (['when', 'i', 'watch', 'a', 'movie', 'like', 'mike', ...], 'neg_train'),\n",
              " (['poster', 'boy', 'for', 'co', '-', 'dependency', ...], 'neg_train'),\n",
              " (['the', 'last', 'of', 'vampire', '-', 'films', ...], 'neg_train'),\n",
              " (['pre', '-', 'review', 'note', ':', 'seeing', 'as', ...], 'neg_train'),\n",
              " (['don', \"'\", 't', 'let', 'this', 'movie', 'fool', ...], 'neg_train'),\n",
              " (['in', 'life', ',', 'eddie', 'murphy', 'and', 'martin', ...], 'neg_train'),\n",
              " (['one', 'of', 'these', 'days', ',', 'i', \"'\", 'll', ...], 'neg_train'),\n",
              " (['i', \"'\", 'm', 'a', 'dedicated', 'fan', 'of', ...], 'neg_train'),\n",
              " (['according', 'to', 'the', 'publicity', 'material', ...], 'neg_train'),\n",
              " (['beware', 'of', 'movies', 'with', 'the', 'director', ...], 'neg_train'),\n",
              " (['at', 'the', 'outset', 'of', 'swordfish', ',', 'john', ...], 'neg_train'),\n",
              " (['warning', ':', 'may', 'contain', 'slight', 'mild', ...], 'neg_train'),\n",
              " (['this', 'was', 'the', 'last', 'carry', 'on', 'movie', ...], 'neg_train'),\n",
              " (['i', 'was', 'going', 'to', 'see', 'ram', 'shrasta', ...], 'neg_train'),\n",
              " (['i', 'still', 'can', \"'\", 't', 'figure', 'out', 'why', ...], 'neg_train'),\n",
              " (['there', \"'\", 's', 'no', 'reason', 'to', 'doubt', ...], 'neg_train'),\n",
              " (['*', '*', '*', 'be', 'warned', '.', '.', '.', 'the', ...], 'neg_train'),\n",
              " (['stallone', 'attempts', 'to', \"'\", 'act', \"'\", 'in', ...], 'neg_train'),\n",
              " (['it', \"'\", 's', 'now', 'the', 'anniversary', 'of', ...], 'neg_train'),\n",
              " (['this', 'movie', 'tries', 'to', 'present', 'itself', ...], 'neg_train'),\n",
              " (['susan', 'granger', \"'\", 's', 'review', 'of', '\"', ...], 'neg_train'),\n",
              " (['the', 'blues', 'brothers', 'was', 'a', 'wonderful', ...], 'neg_train'),\n",
              " (['this', 'movie', 'is', 'written', 'by', 'the', 'man', ...], 'neg_train'),\n",
              " (['talk', 'about', 'beating', 'a', 'dead', 'horse', '!', ...], 'neg_train'),\n",
              " (['in', 'the', 'series', 'of', 'the', 'erotic', ...], 'neg_train'),\n",
              " (['spoiled', 'rich', 'kid', 'kelley', 'morse', '(', ...], 'neg_train'),\n",
              " (['some', 'concepts', 'seem', 'patently', 'hopeless', ...], 'neg_train'),\n",
              " (['the', 'general', \"'\", 's', 'daughter', 'is', 'a', ...], 'neg_train'),\n",
              " (['instinct', 'is', 'the', 'kind', 'of', 'movie', ...], 'neg_train'),\n",
              " (['in', '1989', ',', 'tim', 'burton', 'took', 'the', ...], 'neg_train'),\n",
              " (['in', 'my', 'review', 'of', '\"', 'the', 'spy', 'who', ...], 'neg_train'),\n",
              " (['well', 'arnold', 'has', 'completed', 'the', ...], 'neg_train'),\n",
              " (['the', 'sequel', 'to', 'the', 'fugitive', '(', '1993', ...], 'neg_train'),\n",
              " (['the', 'first', 'scene', 'of', 'operation', 'condor', ...], 'neg_train'),\n",
              " (['call', '\"', 'hush', '\"', '\"', 'stop', 'or', 'my', ...], 'neg_train'),\n",
              " (['director', 'luis', 'mandoki', \"'\", 's', 'last', ...], 'neg_train'),\n",
              " (['how', 'do', 'you', 'judge', 'a', 'film', 'that', ...], 'neg_train'),\n",
              " (['capsule', ':', 'a', 'ham', '-', 'handed', 'and', ...], 'neg_train'),\n",
              " (['apparently', ',', 'when', 'crap', 'calls', ',', ...], 'neg_train'),\n",
              " (['the', 'kids', 'in', 'the', 'hall', 'are', 'an', ...], 'neg_train'),\n",
              " (['\"', 'you', 'can', \"'\", 't', 'have', 'any', 'of', ...], 'neg_train'),\n",
              " (['the', 'characters', 'in', 'jonathan', 'lynn', \"'\", ...], 'neg_train'),\n",
              " ([\"'\", 'bicentennial', 'man', \"'\", 'is', 'a', 'family', ...], 'neg_train'),\n",
              " (['i', 'don', \"'\", 't', 'expect', 'much', 'from', ...], 'neg_train'),\n",
              " (['reading', 'the', 'cast', 'and', 'director', 'for', ...], 'neg_train'),\n",
              " (['remember', 'tom', 'cruise', 'and', 'brian', 'brown', ...], 'neg_train'),\n",
              " (['there', \"'\", 're', 'so', 'many', 'things', 'to', ...], 'neg_train'),\n",
              " (['my', 'giant', 'is', 'two', 'movies', 'for', 'the', ...], 'neg_train'),\n",
              " (['*', '*', '*', 'the', 'following', 'review', ...], 'neg_train'),\n",
              " (['synopsis', ':', 'cro', '-', 'magnon', 'ayla', ...], 'neg_train'),\n",
              " (['a', 'number', 'of', 'critics', 'have', 'decided', ...], 'neg_train'),\n",
              " (['two', 'party', 'guys', 'bob', 'their', 'heads', 'to', ...], 'neg_train'),\n",
              " (['\"', 'first', 'rule', 'of', 'fight', 'club', 'is', ...], 'neg_train'),\n",
              " (['\"', 'with', 'all', 'that', 'education', ',', 'you', ...], 'neg_train'),\n",
              " (['what', 'makes', 'reindeer', 'games', 'even', 'more', ...], 'neg_train'),\n",
              " (['coinciding', 'with', 'the', 'emerging', 'popularity', ...], 'neg_train'),\n",
              " (['synopsis', ':', 'a', 'humorless', 'police', ...], 'neg_train'),\n",
              " (['susan', 'granger', \"'\", 's', 'review', 'of', '\"', ...], 'neg_train'),\n",
              " (['the', '\"', 'disney', 'stick', '-', 'to', '-', 'what', ...], 'neg_train'),\n",
              " (['martial', 'arts', 'master', 'steven', 'seagal', '(', ...], 'neg_train'),\n",
              " (['the', 'first', 'image', 'in', '\"', 'final', ...], 'neg_train'),\n",
              " (['for', 'a', 'good', 'ten', 'years', 'or', 'so', ',', ...], 'neg_train'),\n",
              " (['years', 'ago', ',', 'robin', 'williams', 'made', ...], 'neg_train'),\n",
              " (['by', '-', 'the', '-', 'numbers', ':', 'a', 'film', ...], 'neg_train'),\n",
              " (['chris', 'tucker', 'is', 'one', 'of', 'those', 'guys', ...], 'neg_train'),\n",
              " (['when', 'critics', 'attack', 'seemingly', 'well', '-', ...], 'neg_train'),\n",
              " (['there', '?', 's', 'nothing', 'quite', 'like', 'a', ...], 'neg_train'),\n",
              " (['annie', 'wilson', '(', 'cate', 'blanchett', ')', ',', ...], 'neg_train'),\n",
              " (['if', 'i', 'were', 'one', 'of', 'those', 'arrogant', ...], 'neg_train'),\n",
              " (['suicide', 'is', 'pointless', ',', 'everyone', ...], 'neg_train'),\n",
              " (['one', 'of', 'the', 'contributors', 'to', 'the', ...], 'neg_train'),\n",
              " (['tv', \"'\", 's', 'buffy', 'finds', 'herself', 'on', ...], 'neg_train'),\n",
              " (['at', 'times', ',', 'you', \"'\", 'd', 'think', 'edtv', ...], 'neg_train'),\n",
              " (['\"', 'some', 'houses', 'are', 'born', 'bad', ',', '\"', ...], 'neg_train'),\n",
              " (['let', 'me', 'just', 'start', 'this', 'review', 'off', ...], 'neg_train'),\n",
              " (['the', 'above', 'is', 'dialogue', 'from', 'this', ...], 'neg_train'),\n",
              " (['wild', 'things', 'is', 'a', 'way', 'to', 'steam', ...], 'neg_train'),\n",
              " (['well', ',', 'what', 'are', 'you', 'going', 'to', ...], 'neg_train'),\n",
              " (['there', 'may', 'not', 'be', 'a', 'critic', 'alive', ...], 'neg_train'),\n",
              " (['the', 'formula', 'is', 'simple', '.', 'trap', 'a', ...], 'neg_train'),\n",
              " (['ugh', '.', 'that', 'about', 'sums', 'this', 'movie', ...], 'neg_train'),\n",
              " (['play', 'it', 'to', 'the', 'bone', 'is', 'a', 'punch', ...], 'neg_train'),\n",
              " (['michael', 'richards', 'leaves', 'his', 'spot', 'as', ...], 'neg_train'),\n",
              " (['\"', 'gordy', '\"', 'is', 'not', 'a', 'movie', ',', ...], 'neg_train'),\n",
              " (['the', 'rapid', '-', 'fire', 'formula', 'that', ...], 'neg_train'),\n",
              " (['i', 'am', 'a', 'steven', 'seagal', 'fan', '.', 'i', ...], 'neg_train'),\n",
              " (['there', 'are', 'scenes', 'in', '\"', 'the', 'big', ...], 'neg_train'),\n",
              " (['the', 'realm', 'of', 'science', 'fiction', 'has', ...], 'neg_train'),\n",
              " (['vampires', 'starts', 'out', 'almost', 'in', 'the', ...], 'neg_train'),\n",
              " (['according', 'to', 'hitchcock', 'and', 'various', ...], 'neg_train'),\n",
              " (['frank', 'detorri', \"'\", 's', '(', 'bill', 'murray', ...], 'neg_train'),\n",
              " (['back', 'in', '1980s', ',', 'chuck', 'norris', 'used', ...], 'neg_train'),\n",
              " (['you', 'should', 'have', 'heard', 'the', 'old', ...], 'neg_train'),\n",
              " (['`', 'bats', \"'\", 'is', 'an', 'insulting', 'slap', ...], 'neg_train'),\n",
              " (['when', 'i', 'arrived', 'in', 'paris', 'in', 'june', ...], 'neg_train'),\n",
              " (['you', 'would', 'think', 'that', 'this', 'film', \"'\", ...], 'neg_train'),\n",
              " (['one', '-', 'sided', '\"', 'doom', 'and', 'gloom', '\"', ...], 'neg_train'),\n",
              " (['well', 'i', 'guess', 'it', \"'\", 's', 'that', 'time', ...], 'neg_train'),\n",
              " (['i', \"'\", 'm', 'not', 'sure', 'who', 'the', 'genius', ...], 'neg_train'),\n",
              " (['set', 'in', 'harlem', 'during', 'the', 'great', ...], 'neg_train'),\n",
              " (['one', 'of', 'my', 'brother', \"'\", 's', 'favorite', ...], 'neg_train'),\n",
              " (['robin', 'williams', 'has', 'the', 'rarest', 'of', ...], 'neg_train'),\n",
              " (['capsule', ':', 'the', 'weakest', 'and', 'least', ...], 'neg_train'),\n",
              " (['plot', ':', 'two', 'teen', 'couples', 'go', 'to', ...], 'neg_train'),\n",
              " (['are', 'you', 'like', 'me', '?', 'do', 'you', 'get', ...], 'neg_train'),\n",
              " (['overblown', 'remake', 'of', 'the', '1963', 'robert', ...], 'neg_train'),\n",
              " (['i', 'have', 'a', 'confession', '.', 'even', 'though', ...], 'neg_train'),\n",
              " (['the', 'classic', 'story', '&', 'the', 'production', ...], 'neg_train'),\n",
              " (['by', 'phil', 'curtolo', '\"', 'madonna', '-', ...], 'neg_train'),\n",
              " (['please', 'don', \"'\", 't', 'mind', 'this', 'windbag', ...], 'neg_train'),\n",
              " (['libby', 'parsons', '(', 'ashley', 'judd', ')', 'has', ...], 'neg_train'),\n",
              " (['sandra', 'bullock', 'in', 'high', 'heels', 'and', ...], 'neg_train'),\n",
              " (['\"', 'the', '44', 'caliber', 'killer', 'has', ...], 'neg_train'),\n",
              " (['every', 'now', 'and', 'then', ',', 'reviewers', ...], 'neg_train'),\n",
              " (['wyatt', 'earp', 'details', 'thirty', '-', 'five', ...], 'neg_train'),\n",
              " (['all', 'right', ',', 'all', 'right', ',', 'we', 'get', ...], 'neg_train'),\n",
              " (['the', 'premise', 'of', 'turbulence', 'is', 'i', \"'\", ...], 'neg_train'),\n",
              " (['8mm', 'is', 'not', 'going', 'to', 'enlighten', ...], 'neg_train'),\n",
              " (['54', 'is', 'dull', ',', 'perfunctory', ',', ...], 'neg_train'),\n",
              " (['as', 'any', 'reasonable', 'human', 'being', 'would', ...], 'neg_train'),\n",
              " (['this', 'talky', ',', 'terribly', '-', 'plotted', ...], 'neg_train'),\n",
              " (['the', 'original', 'babe', 'gets', 'my', 'vote', 'as', ...], 'neg_train'),\n",
              " (['it', 'used', 'to', 'be', 'that', 'not', 'just', ...], 'neg_train'),\n",
              " (['writing', 'a', 'screenplay', 'for', 'a', 'thriller', ...], 'neg_train'),\n",
              " (['after', 'seeing', 'blaze', 'and', 'driving', 'miss', ...], 'neg_train'),\n",
              " (['tim', 'burton', 'has', 'now', 'completed', 'his', ...], 'neg_train'),\n",
              " (['this', 'independent', 'film', 'written', 'and', ...], 'neg_train'),\n",
              " (['robin', 'williams', ',', 'this', 'time', 'without', ...], 'neg_train'),\n",
              " (['numerous', 'comparisons', 'can', 'be', 'made', ...], 'neg_train'),\n",
              " (['here', \"'\", 's', 'something', 'to', 'chew', 'on', ...], 'neg_train'),\n",
              " (['\"', 'you', 'damn', 'dirty', 'apes', '!', '\"', 'that', ...], 'neg_train'),\n",
              " (['you', 'know', 'the', 'plot', ':', 'a', 'dimwit', ...], 'neg_train'),\n",
              " (['what', 'would', 'inspire', 'someone', 'who', ...], 'neg_train'),\n",
              " (['janeane', 'garofalo', 'in', 'a', 'romantic', ...], 'neg_train'),\n",
              " (['according', 'to', 'popular', 'film', 'opinion', ',', ...], 'neg_train'),\n",
              " (['capsule', ':', 'not', 'as', 'bad', 'a', 'sequel', ...], 'neg_train'),\n",
              " (['at', 'first', 'i', 'was', 'intrigued', 'by', 'the', ...], 'neg_train'),\n",
              " (['some', 'movies', \"'\", 'pre', '-', 'release', 'buzz', ...], 'neg_train'),\n",
              " (['i', 'was', 'recently', 'told', 'that', 'in', 'china', ...], 'neg_train'),\n",
              " (['\"', 'america', \"'\", 's', 'sweethearts', '\"', 'has', ...], 'neg_train'),\n",
              " (['another', 'formula', \"'\", 'feel', 'good', \"'\", ...], 'neg_train'),\n",
              " (['i', 'cried', 'during', '_babe_', '.', 'i', 'admit', ...], 'neg_train'),\n",
              " (['it', \"'\", 's', 'actually', 'not', 'so', 'bad', ...], 'neg_train'),\n",
              " (['girl', '6', 'is', ',', 'in', 'a', 'word', ',', 'a', ...], 'neg_train'),\n",
              " (['aspiring', 'broadway', 'composer', 'robert', '(', ...], 'neg_train'),\n",
              " (['synopsis', ':', 'a', 'small', 'town', 'thug', ...], 'neg_train'),\n",
              " (['perhaps', 'if', 'the', 'impostors', 'didn', \"'\", 't', ...], 'neg_train'),\n",
              " (['louie', 'is', 'a', 'trumpeter', 'swan', 'with', 'no', ...], 'neg_train'),\n",
              " (['long', 'time', 'buddies', 'and', 'neil', 'diamond', ...], 'neg_train'),\n",
              " (['when', 'the', 'mediums', 'in', 'question', 'are', ...], 'neg_train'),\n",
              " (['woody', 'allen', 'is', 'one', 'of', 'the', 'most', ...], 'neg_train'),\n",
              " (['the', 'working', 'title', 'for', 'no', 'looking', ...], 'neg_train'),\n",
              " (['200', 'cigarettes', 'takes', 'place', 'on', 'new', ...], 'neg_train'),\n",
              " (['wow', ',', 'a', 'film', 'without', 'any', ...], 'neg_train'),\n",
              " (['over', '40', 'years', 'ago', ',', 'a', 'japanese', ...], 'neg_train'),\n",
              " (['a', 'slight', 'romantic', 'comedy', 'with', 'a', ...], 'neg_train'),\n",
              " (['starring', 'ben', 'stiller', ',', 'elizabeth', ...], 'neg_train'),\n",
              " (['written', 'by', 'david', 'j', '.', 'schow', 'and', ...], 'neg_train'),\n",
              " (['as', 'the', 'twin', 'surfer', 'dudes', ',', 'stew', ...], 'neg_train'),\n",
              " (['(', 'dreamworks', 'skg', ')', 'running', 'time', ':', ...], 'neg_train'),\n",
              " (['gord', 'brody', '(', 'tom', 'green', ')', 'is', 'an', ...], 'neg_train'),\n",
              " (['i', 'read', 'the', 'new', 'yorker', 'magazine', ...], 'neg_train'),\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "pos_train = [(movie_reviews.words(fileid), 'pos_train') for fileid in pos_train_ids]\n",
        "pos_test = [(movie_reviews.words(fileid), 'pos_test') for fileid in pos_test_ids]\n",
        "neg_train = [(movie_reviews.words(fileid), 'neg_train') for fileid in neg_train_ids]\n",
        "neg_test = [(movie_reviews.words(fileid), 'neg_test') for fileid in neg_test_ids]\n",
        "\n",
        "constructed_list = pos_train + neg_train + pos_test + neg_test\n",
        "constructed_list\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "kA8AJhWLqe5S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a865726-3af8-4422-c8de-26c285aeefe4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The size of training is 1400\n",
            "The size of testing is 600\n"
          ]
        }
      ],
      "source": [
        "check_size_training = len(pos_train) + len(neg_train)\n",
        "check_size_testing = len(pos_test) + len(neg_test)\n",
        "\n",
        "print(f\"The size of training is {check_size_training}\")\n",
        "print(f\"The size of testing is {check_size_testing}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3SLme3Oqe5S"
      },
      "source": [
        "## Document Representations\n",
        "\n",
        "Currently, each review / document is represented as a list of tokens.  In many simple applications, the order of words in a document is deemed irrelevant and we use a bag-of-words representation of the document.  We can create a bag-of-words using a dictionary (as we did in Lab_2_2 when considering the size of the vocabulary) or we can use a library function such as FreqDist from nltk.probability (or Counter from Collections).  In the cell below, I generate the bag-of-words for the first review in the training set using nltk's FreqDist.  You can think of this as like a dictionary but with extra benefits.  For example, later on in the lab, we will see it has useful methods which allow the document representations to be added and subtracted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRTriMZIqe5S"
      },
      "outputs": [],
      "source": [
        "from nltk.probability import FreqDist\n",
        "\n",
        "doc1 = FreqDist(training[0][0])\n",
        "doc1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4qdRQEeqe5T"
      },
      "source": [
        "### Exercise 2.1\n",
        "\n",
        "Write code to use FreqDist to construct a bag-of-words representation for each document in the training and testing sets.  Store the results in two lists, `training_basic` and `testing_basic`.  Don't lose the annotations as to whether each review is positive or negative!  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Pesd-Rjqe5T"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-sFdi8Jqe5T"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJd0x75aqe5U"
      },
      "source": [
        "You will notice of course that many of the words in your representations of documents are punctuation and stopwords.  This is because we haven't done any pre-processing of the wordlists.\n",
        "\n",
        "### Exercise 2.2\n",
        "\n",
        "Decide which of the following pre-processing steps to apply to the word lists:-\n",
        "* case normalisation\n",
        "* number normalisation\n",
        "* punctuation removal\n",
        "* stopword removal\n",
        "* stemmming / lemmatisation\n",
        "\n",
        "\n",
        "Apply these preprocessing steps to the original wordlist representations (stored in `training` and `testing`).  Then recreate the bag-of-words representations, storing the results in `training_norm` and `testing_norm`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DtkW4fzYqe5U"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLx5ja1aqe5U"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTGHJWSd7iQ5"
      },
      "source": [
        "## Creating word lists\n",
        "The next section will explain how to use a sentiment classifier that bases its decisions on word lists. The classifier requires a list of words indicating positive sentiment, and a second list of words indicating negative sentiment. Given positive and negative word lists, a document's overall sentiment is determined based on counts of occurrences of words that occur in the two lists. In this section we are concerned with the creation of the word lists. We will be considering both hand-crafted lists and automatically generated lists."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "572x5pEP7iQ6"
      },
      "source": [
        "### Exercise 3.1\n",
        "\n",
        "- Create a reasonably long hand-crafted list of words that you think indicate positive sentiment.\n",
        "- Create a reasonably long hand-crafted list of words that indicate negative sentiment.\n",
        "\n",
        "Use the following cells to store these lists in the variables `my_positive_word_list` and `my_negative_word_list`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPzluDd-7iQ6"
      },
      "outputs": [],
      "source": [
        "my_positive_word_list = [\"good\",\"great\",\"lovely\"] # extend this one or put your own list here\n",
        "my_negative_word_list = [\"bad\", \"terrible\", \"awful\"] # extend this one or put your own list here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nQhC0Zaqe5W"
      },
      "source": [
        "Now lets see how often each of those words occurs in total in our positive and negative training data.  First, lets create a total of the FreqDists for positive data and for negative data.  As these are FreqDists (rather than simple dictionaries), we can do this as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Tg_0bttqe5X"
      },
      "outputs": [],
      "source": [
        "pos_freq_dist=FreqDist()\n",
        "neg_freq_dist=FreqDist()\n",
        "\n",
        "for reviewDist,label in training_norm:\n",
        "    if label=='pos':\n",
        "        pos_freq_dist+=reviewDist\n",
        "    else:\n",
        "        neg_freq_dist+=reviewDist\n",
        "\n",
        "pos_freq_dist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNUtrGjVqe5Y"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RW9BMqP37iRH"
      },
      "source": [
        "### Exercise 3.2\n",
        "In the blank code cell below write code that uses the total frequency distributions `pos_freq_dist` and `neg_freq_dist` and the word lists `my_positive_word_list` and `my_negative_word_list` created earlier to determine whether or not the review data conforms to your expectations. In particular, whether:\n",
        "- the words you expected to indicate positive sentiment actually occur more frequently in positive reviews than negative reviews\n",
        "- the words you expected to indicate negative sentiment actually occur more frequently in negative reviews than positive reviews.\n",
        "\n",
        "You could display your findings in a table using pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPRJHuET7iRH"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4aR84LE7iRL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkfwFU4v7iRO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OefXeFaKqe5b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bXExCJp7iRS"
      },
      "source": [
        "### Exercise 3.3\n",
        "Now, you are going to create positive and negative word lists automatically from the training data. In order to do this:\n",
        "\n",
        "1. write two new functions to help with automating the process of generating wordlists.\n",
        "\n",
        "    - `most_frequent_words` - this function should take THREE arguments: 2 frequency distributions and a natural number, k. It should order words by how much more they occur in one frequency distribution than the other.   It should then return the top k highest scoring words. You might want to use the `most_common` method from the `FreqDist` class - this returns a list of word, frequency pairs ordered by frequency.  You might also or alternatively want to use pythons built-in `sorted` function\n",
        "    - `words_above_threshold` - this function also takes three arguments: 2 frequency distributions and a natural number, k. Again, it should order words by how much more they occur in one distribution than the other.  It should return all of the words that have a score greater than k.\n",
        "\n",
        "2. Using the training data, create two sets of positive and negative word lists using these functions (1 set with each function).\n",
        "3.  Display these 4 lists (possibly in a `Pandas` dataframe?)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6hw9SFM7iRY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jtwxYJmQ7iRb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kP84olqo7iRf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABq5Sb0j_j2p"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idr8XYkWAmfl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FaqsrbFTAmwI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzVP-hJH7iRi"
      },
      "source": [
        "## Creating a word list based classifier\n",
        "Now you have a number of word lists for use with a classifier.\n",
        "> Make sure you understand the following code, which will be used as the basis for creating a word list based classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSaLWU_A7iRi"
      },
      "outputs": [],
      "source": [
        "from nltk.classify.api import ClassifierI\n",
        "import random\n",
        "\n",
        "class SimpleClassifier(ClassifierI):\n",
        "\n",
        "    def __init__(self, pos, neg):\n",
        "        self._pos = pos\n",
        "        self._neg = neg\n",
        "\n",
        "    def classify(self, words):\n",
        "        score = 0\n",
        "\n",
        "        # add code here that assigns an appropriate value to score\n",
        "        return \"neg\" if score < 0 else \"pos\"\n",
        "\n",
        "    ##we don't actually need to define the classify_many method as it is provided in ClassifierI\n",
        "    #def classify_many(self, docs):\n",
        "    #    return [self.classify(doc) for doc in docs]\n",
        "\n",
        "    def labels(self):\n",
        "        return (\"pos\", \"neg\")\n",
        "\n",
        "#Example usage:\n",
        "\n",
        "classifier = SimpleClassifier(my_positive_word_list, my_negative_word_list)\n",
        "classifier.classify(FreqDist(\"This movie was great\".split()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irq5PVOc7iRl"
      },
      "source": [
        "### Exercise 3.1\n",
        "\n",
        "- Copy the above code cell and move it to below this one. Then complete the `classify` method in the above code as specified below.\n",
        "- Test your classifier on several very simple hand-crafted examples to verify that you have implemented `classify` correctly.\n",
        "\n",
        "The classifier is initialised with a list of positive words, and a list of negative words. The words of a document are passed to the `classify` method (which is partially completed in the above code fragment). The `classify` method should be defined so that each occurrence of a negative word decrements `score`, and each occurrence of a positive word increments `score`.\n",
        "- For `score` less than 0, \"`neg`\" for negative should be returned.\n",
        "- For `score` greater than 0,  \"`pos`\" for positive should returned.\n",
        "- For `score` of 0, the classification decision should be made randomly (see https://docs.python.org/3/library/random.html).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0UXUyFHM7iRm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "GRJWPhUF7iRo"
      },
      "source": [
        "### Exercise 3.2\n",
        "* Extend your SimpleClassifier class so that it has a `train` function which will derive the wordlists from training data.  You could build a separate class for each way of automatically deriving wordlists (which both inherit from SimpleClassifier) OR a single class which takes an extra parameter at training time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KT1PbIao7iRp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h85qqrOV7iRr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3uM8En0_7iRu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fWoIb8dDYzR"
      },
      "source": [
        "Try out your classifier on the test data.  We will look at how to evaluate classifiers in the next part, but in an ideal world, most of the positive test items will have been classified as 'P' and most of the negative test items will have been classified as 'N'.  Note that the batch_classify method takes a list of unlabelled documents so you can't give it a list of pairs (where each pair is doc and a label).  You can either use a list comprehension or the <code>zip(*list_of_pairs)</code> function to split a list of pairs into a pair of lists."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6fQs92SVu39"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFCEF0rx7iRx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Us0zxFpsqe5g"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9MTBKOuDPU9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yuS6Urkaqe5g"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nphj7NkSqe5g"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}